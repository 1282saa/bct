{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ë¹…ì½˜í…ŒìŠ¤íŠ¸ - ë°°ë‹¬ ì„œë¹„ìŠ¤ì™€ íì—… ê´€ê³„ ë¶„ì„\n",
    "\n",
    "## ğŸ“‹ ë¶„ì„ ê°œìš”\n",
    "\n",
    "**ì£¼ì œ**: ì†Œìƒê³µì¸ ë°°ë‹¬ í˜„í™©ì´ íì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„  \n",
    "**ì •ì±… ë°°ê²½**: ì„±ë™êµ¬ ë•¡ê²¨ìš” ì•± (ìˆ˜ìˆ˜ë£Œ 2%, 2023ë…„ 5ì›” ì‹œí–‰)  \n",
    "**ëª©í‘œ**: 11ê°œ ê°€ì„¤ ê²€ì¦ì„ í†µí•œ íì—… ìœ„í—˜ ìš”ì¸ íŒŒì•… ë° ì†”ë£¨ì…˜ ì œì•ˆ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¬ ê²€ì¦ ê°€ì„¤\n",
    "\n",
    "| ì½”ë“œ | ê°€ì„¤ ë‚´ìš© | ê²€ì¦ ë°©ë²• |\n",
    "|------|-----------|----------|\n",
    "| **H1** | íì—… ê°€ë§¹ì ì€ ë¹„íì—… ê°€ë§¹ì ë³´ë‹¤ ë§¤ì¶œë“±ê¸‰ì´ ë‚®ì„ ê²ƒì´ë‹¤ | t-test, Mann-Whitney U |\n",
    "| **H2** | 2023 Q1 ëŒ€ë¹„ 2024 Q4ì— ë°°ë‹¬ ì§€í‘œê°€ ì¦ê°€í–ˆì„ ê²ƒì´ë‹¤ | ì‹œê³„ì—´ ë¹„êµ |\n",
    "| **H3** | 2023ë…„ ëŒ€ë¹„ 2024ë…„ì— ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨ì´ ì¦ê°€í–ˆì„ ê²ƒì´ë‹¤ | ë¹„ìœ¨ ë¹„êµ |\n",
    "| **H4** | ë°°ë‹¬ë§¤ì¶œ ì¡´ì¬ì‹œ ì·¨ì†Œìœ¨ ë°ì´í„° ê²°ì¸¡ì¹˜ê°€ ë” ì ì„ ê²ƒì´ë‹¤ | ì¹´ì´ì œê³± ê²€ì • |\n",
    "| **H5** | ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ì´ ë†’ì„ìˆ˜ë¡ íì—… í™•ë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤ | ë¡œì§€ìŠ¤í‹± íšŒê·€ |\n",
    "| **H6** | ì·¨ì†Œìœ¨ì´ ë†’ì„ìˆ˜ë¡ íì—… í™•ë¥ ì´ ë†’ì„ ê²ƒì´ë‹¤ | ë¡œì§€ìŠ¤í‹± íšŒê·€ |\n",
    "| **H7** | ê³ ê° ë‹¤ì–‘ì„±ì´ ë†’ì„ìˆ˜ë¡ ìƒì¡´ ê°€ëŠ¥ì„±ì´ ë†’ì„ ê²ƒì´ë‹¤ | Shannon Entropy, íšŒê·€ |\n",
    "| **H8** | ìƒê¶Œì— ë”°ë¼ íì—…ë¥ ì˜ ì°¨ì´ê°€ ìœ ì˜í•˜ë‹¤ | ì¹´ì´ì œê³± ê²€ì •, ANOVA |\n",
    "| **H9** | ìš´ì˜ê°œì›” ìˆ˜ê°€ ì§§ì„ìˆ˜ë¡ íì—… ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ | ë¡œì§€ìŠ¤í‹± íšŒê·€ |\n",
    "| **H10** | ë™ì¼ ì—…ì¢… ë‚´ í‰ê·  ëŒ€ë¹„ ë§¤ì¶œì´ ë‚®ì„ìˆ˜ë¡ íì—…ìœ„í—˜ì´ ë†’ë‹¤ | ë¡œì§€ìŠ¤í‹± íšŒê·€ |\n",
    "| **H11** | ê±°ì£¼í˜•Â·ì§ì¥í˜•Â·ìœ ë™ì¸êµ¬ ê³ ê° ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ íì—…ìœ„í—˜ì´ ë‚®ë‹¤ | ë¡œì§€ìŠ¤í‹± íšŒê·€ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_palette('husl')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'big_data_merged.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ë°ì´í„° ë¡œë“œ\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbig_data_merged.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124më°ì´í„° shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mê¸°ê°„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTA_YM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTA_YM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Users/file/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Users/file/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Users/file/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/Users/file/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Users/file/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'big_data_merged.csv'"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('/Users/yeong-gwang/Documents/ë°°ì›€ ì˜¤ì „ 1.38.42/ì™¸ë¶€/ê³µëª¨ì „/ë¹…ì½˜í…ŒìŠ¤íŠ¸/Project/work/ver3_/1011/data/big_data_merged.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"ë°ì´í„° shape: {df.shape}\")\n",
    "print(f\"\\nê¸°ê°„: {df['TA_YM'].min()} ~ {df['TA_YM'].max()}\")\n",
    "print(f\"\\nì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ\")\n",
    "\n",
    "# ê¸°ë³¸ ë³€ìˆ˜ ìƒì„±\n",
    "df['íì—…ì—¬ë¶€'] = df['MCT_ME_D'].notna().astype(int)\n",
    "df['ë°°ë‹¬í™œì„±í™”'] = (df['DLV_SAA_RAT'].fillna(-999999) > 0).astype(int)\n",
    "\n",
    "# ì‹œê³„ì—´ ë³€ìˆ˜\n",
    "df['ì—°ë„'] = df['TA_YM'].astype(str).str[:4]\n",
    "df['ì›”'] = df['TA_YM'].astype(str).str[4:6].astype(int)\n",
    "df['ë¶„ê¸°'] = df['ì›”'].apply(lambda x: f\"Q{(x-1)//3 + 1}\")\n",
    "df['ë…„ë¶„ê¸°'] = df['ì—°ë„'] + '-' + df['ë¶„ê¸°']\n",
    "\n",
    "print(f\"\\níì—…ë¥ : {df['íì—…ì—¬ë¶€'].mean()*100:.2f}%\")\n",
    "print(f\"ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {df['ë°°ë‹¬í™œì„±í™”'].mean()*100:.2f}%\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h1",
   "metadata": {},
   "source": [
    "---\n",
    "## H1: íì—… ê°€ë§¹ì  vs ë¹„íì—… ê°€ë§¹ì  ë§¤ì¶œë“±ê¸‰ ì°¨ì´\n",
    "\n",
    "**ê°€ì„¤**: íì—… ê°€ë§¹ì ì€ ë¹„íì—… ê°€ë§¹ì ë³´ë‹¤ ë§¤ì¶œë“±ê¸‰ì´ ë‚®ì„ ê²ƒì´ë‹¤  \n",
    "**ê²€ì¦**: t-test, Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§¤ì¶œë“±ê¸‰ ìˆ«ìí™”\n",
    "sales_map = {\n",
    "    '1_10%ì´í•˜': 1, '2_10-25%': 2, '3_25-50%': 3,\n",
    "    '4_50-75%': 4, '5_75-90%': 5, '6_90%ì´ˆê³¼(í•˜ìœ„ 10% ì´í•˜)': 6\n",
    "}\n",
    "df['ë§¤ì¶œë“±ê¸‰_ìˆ˜ì¹˜'] = df['RC_M1_SAA'].map(sales_map)\n",
    "\n",
    "non_closure_sales = df[df['íì—…ì—¬ë¶€']==0]['ë§¤ì¶œë“±ê¸‰_ìˆ˜ì¹˜'].dropna()\n",
    "closure_sales = df[df['íì—…ì—¬ë¶€']==1]['ë§¤ì¶œë“±ê¸‰_ìˆ˜ì¹˜'].dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"H1: íì—…/ë¹„íì—… ê°€ë§¹ì  ë§¤ì¶œë“±ê¸‰ ë¹„êµ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\në¹„íì—… ê°€ë§¹ì  í‰ê·  ë§¤ì¶œë“±ê¸‰: {non_closure_sales.mean():.2f}\")\n",
    "print(f\"íì—… ê°€ë§¹ì  í‰ê·  ë§¤ì¶œë“±ê¸‰: {closure_sales.mean():.2f}\")\n",
    "\n",
    "# t-test\n",
    "t_stat, t_pval = stats.ttest_ind(non_closure_sales, closure_sales)\n",
    "print(f\"\\nt-test ê²°ê³¼:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {t_pval:.6f}\")\n",
    "\n",
    "# Mann-Whitney U test\n",
    "u_stat, u_pval = stats.mannwhitneyu(non_closure_sales, closure_sales, alternative='two-sided')\n",
    "print(f\"\\nMann-Whitney U test ê²°ê³¼:\")\n",
    "print(f\"  U-statistic: {u_stat:.0f}\")\n",
    "print(f\"  p-value: {u_pval:.6f}\")\n",
    "\n",
    "# ê²°ë¡ \n",
    "if t_pval < 0.05:\n",
    "    result = \"ì±„íƒ\"\n",
    "    interpretation = f\"íì—… ê°€ë§¹ì ì˜ ë§¤ì¶œë“±ê¸‰ì´ ìœ ì˜í•˜ê²Œ {'ë‚®ìŒ' if closure_sales.mean() < non_closure_sales.mean() else 'ë†’ìŒ'}\"\n",
    "else:\n",
    "    result = \"ê¸°ê°\"\n",
    "    interpretation = \"ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ê²°ë¡ : H1 {result}\")\n",
    "print(f\"í•´ì„: {interpretation}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ë°•ìŠ¤í”Œë¡¯\n",
    "data_for_box = pd.DataFrame({\n",
    "    'ë§¤ì¶œë“±ê¸‰': list(non_closure_sales) + list(closure_sales),\n",
    "    'íì—…ì—¬ë¶€': ['ë¹„íì—…']*len(non_closure_sales) + ['íì—…']*len(closure_sales)\n",
    "})\n",
    "sns.boxplot(data=data_for_box, x='íì—…ì—¬ë¶€', y='ë§¤ì¶œë“±ê¸‰', ax=axes[0])\n",
    "axes[0].set_title('íì—… ì—¬ë¶€ë³„ ë§¤ì¶œë“±ê¸‰ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)')\n",
    "axes[0].set_ylabel('ë§¤ì¶œë“±ê¸‰ (1=ë‚®ìŒ, 6=ë†’ìŒ)')\n",
    "\n",
    "# ë°”ì´ì˜¬ë¦° í”Œë¡¯\n",
    "sns.violinplot(data=data_for_box, x='íì—…ì—¬ë¶€', y='ë§¤ì¶œë“±ê¸‰', ax=axes[1])\n",
    "axes[1].set_title('íì—… ì—¬ë¶€ë³„ ë§¤ì¶œë“±ê¸‰ ë¶„í¬ (ë°”ì´ì˜¬ë¦° í”Œë¡¯)')\n",
    "axes[1].set_ylabel('ë§¤ì¶œë“±ê¸‰ (1=ë‚®ìŒ, 6=ë†’ìŒ)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h2",
   "metadata": {},
   "source": [
    "---\n",
    "## H2: 2023 Q1 vs 2024 Q4 ë°°ë‹¬ ì§€í‘œ ì¦ê°€\n",
    "\n",
    "**ê°€ì„¤**: 2023ë…„ 1ë¶„ê¸° ëŒ€ë¹„ 2024ë…„ 4ë¶„ê¸°ì— ë°°ë‹¬ ê´€ë ¨ ì§€í‘œê°€ ì¦ê°€í–ˆì„ ê²ƒì´ë‹¤  \n",
    "**ë°°ê²½**: ì„±ë™êµ¬ ë•¡ê²¨ìš” ì•± íš¨ê³¼ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h2_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ê¸°ë³„ ë°°ë‹¬ ì§€í‘œ\n",
    "quarterly_stats = df.groupby('ë…„ë¶„ê¸°').agg({\n",
    "    'ë°°ë‹¬í™œì„±í™”': ['sum', 'count', 'mean'],\n",
    "    'DLV_SAA_RAT': lambda x: x[x > 0].mean() if (x > 0).any() else 0\n",
    "}).round(4)\n",
    "\n",
    "quarterly_stats.columns = ['ë°°ë‹¬í™œì„±ê°€ë§¹ì ìˆ˜', 'ì´ê°€ë§¹ì ìˆ˜', 'ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨', 'í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨']\n",
    "quarterly_stats['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'] = (quarterly_stats['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'] * 100).round(2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"H2: 2023 Q1 vs 2024 Q4 ë°°ë‹¬ ì§€í‘œ ë¹„êµ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\në¶„ê¸°ë³„ ë°°ë‹¬ ì§€í‘œ:\")\n",
    "print(quarterly_stats)\n",
    "\n",
    "if '2023-Q1' in quarterly_stats.index and '2024-Q4' in quarterly_stats.index:\n",
    "    q1_2023 = quarterly_stats.loc['2023-Q1']\n",
    "    q4_2024 = quarterly_stats.loc['2024-Q4']\n",
    "\n",
    "    print(f\"\\n2023-Q1:\")\n",
    "    print(f\"  ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {q1_2023['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']:.2f}%\")\n",
    "    print(f\"  í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨: {q1_2023['í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨']:.2f}%\")\n",
    "\n",
    "    print(f\"\\n2024-Q4:\")\n",
    "    print(f\"  ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {q4_2024['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']:.2f}%\")\n",
    "    print(f\"  í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨: {q4_2024['í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨']:.2f}%\")\n",
    "\n",
    "    change_rate = q4_2024['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'] - q1_2023['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']\n",
    "    change_sales = q4_2024['í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨'] - q1_2023['í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨']\n",
    "\n",
    "    print(f\"\\në³€í™”ëŸ‰:\")\n",
    "    print(f\"  ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {change_rate:+.2f}%p\")\n",
    "    print(f\"  í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨: {change_sales:+.2f}%p\")\n",
    "\n",
    "    if change_rate > 0 and change_sales > 0:\n",
    "        result = \"ì±„íƒ\"\n",
    "        interpretation = \"ë°°ë‹¬ ì§€í‘œ ëª¨ë‘ ì¦ê°€ í™•ì¸ (ë•¡ê²¨ìš” ì•± íš¨ê³¼)\"\n",
    "    elif change_rate > 0:\n",
    "        result = \"ë¶€ë¶„ ì±„íƒ\"\n",
    "        interpretation = \"ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨ë§Œ ì¦ê°€\"\n",
    "    else:\n",
    "        result = \"ê¸°ê°\"\n",
    "        interpretation = \"ë°°ë‹¬ ì§€í‘œ ì¦ê°€í•˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ê²°ë¡ : H2 {result}\")\n",
    "    print(f\"í•´ì„: {interpretation}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h2_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨ ì¶”ì„¸\n",
    "axes[0].plot(quarterly_stats.index, quarterly_stats['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'], \n",
    "             marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0].set_xlabel('ë¶„ê¸°', fontsize=12)\n",
    "axes[0].set_ylabel('ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨ (%)', fontsize=12)\n",
    "axes[0].set_title('ë¶„ê¸°ë³„ ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨ ì¶”ì„¸', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ë•¡ê²¨ìš” ì‹œí–‰ ì‹œì  í‘œì‹œ (2023-Q2)\n",
    "if '2023-Q2' in quarterly_stats.index:\n",
    "    q2_idx = list(quarterly_stats.index).index('2023-Q2')\n",
    "    axes[0].axvline(x=q2_idx, color='red', linestyle='--', alpha=0.7, label='ë•¡ê²¨ìš” ì‹œí–‰ (2023 Q2)')\n",
    "    axes[0].legend()\n",
    "\n",
    "# í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨ ì¶”ì„¸\n",
    "axes[1].plot(quarterly_stats.index, quarterly_stats['í‰ê· ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨'], \n",
    "             marker='s', linewidth=2, markersize=8, color='coral')\n",
    "axes[1].set_xlabel('ë¶„ê¸°', fontsize=12)\n",
    "axes[1].set_ylabel('í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨ (%)', fontsize=12)\n",
    "axes[1].set_title('ë¶„ê¸°ë³„ í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨ ì¶”ì„¸', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "if '2023-Q2' in quarterly_stats.index:\n",
    "    axes[1].axvline(x=q2_idx, color='red', linestyle='--', alpha=0.7, label='ë•¡ê²¨ìš” ì‹œí–‰ (2023 Q2)')\n",
    "    axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h3",
   "metadata": {},
   "source": [
    "---\n",
    "## H3: 2023ë…„ vs 2024ë…„ ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨ ì¦ê°€\n",
    "\n",
    "**ê°€ì„¤**: 2023ë…„ ëŒ€ë¹„ 2024ë…„ì— ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨ì´ ì¦ê°€í–ˆì„ ê²ƒì´ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h3_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ë„ë³„ ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨\n",
    "yearly_delivery = df.groupby('ì—°ë„')['ë°°ë‹¬í™œì„±í™”'].agg(['sum', 'count', 'mean'])\n",
    "yearly_delivery.columns = ['ë°°ë‹¬í™œì„±ê°€ë§¹ì ', 'ì´ê°€ë§¹ì ', 'ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']\n",
    "yearly_delivery['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'] = (yearly_delivery['ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨'] * 100).round(2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"H3: 2023ë…„ vs 2024ë…„ ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nì—°ë„ë³„ ë°°ë‹¬ í™œì„±í™”:\")\n",
    "print(yearly_delivery)\n",
    "\n",
    "if '2023' in yearly_delivery.index and '2024' in yearly_delivery.index:\n",
    "    rate_2023 = yearly_delivery.loc['2023', 'ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']\n",
    "    rate_2024 = yearly_delivery.loc['2024', 'ë°°ë‹¬í™œì„±í™”ë¹„ìœ¨']\n",
    "\n",
    "    print(f\"\\n2023ë…„ ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {rate_2023:.2f}%\")\n",
    "    print(f\"2024ë…„ ë°°ë‹¬ í™œì„±í™” ë¹„ìœ¨: {rate_2024:.2f}%\")\n",
    "    print(f\"ì¦ê°€ëŸ‰: {rate_2024 - rate_2023:+.2f}%p\")\n",
    "\n",
    "    if rate_2024 > rate_2023:\n",
    "        result = \"ì±„íƒ\"\n",
    "        interpretation = \"ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨ ì¦ê°€\"\n",
    "    else:\n",
    "        result = \"ê¸°ê°\"\n",
    "        interpretation = \"ì¦ê°€í•˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ê²°ë¡ : H3 {result}\")\n",
    "    print(f\"í•´ì„: {interpretation}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h4",
   "metadata": {},
   "source": [
    "---\n",
    "## H4: ë°°ë‹¬ í™œì„±í™”ì‹œ ì·¨ì†Œìœ¨ ê²°ì¸¡ì¹˜ ê°ì†Œ\n",
    "\n",
    "**ê°€ì„¤**: ë°°ë‹¬ë§¤ì¶œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê°€ë§¹ì ì˜ ê²½ìš° ì·¨ì†Œìœ¨ ë°ì´í„° ê²°ì¸¡ì¹˜ê°€ ë” ì ì„ ê²ƒì´ë‹¤  \n",
    "**í•´ì„**: ë°°ë‹¬ ì£¼ë¬¸ì—ì„œ ì·¨ì†Œê°€ ë” ë¹ˆë²ˆí•˜ê²Œ ë°œìƒí•˜ì—¬ ì·¨ì†Œìœ¨ ë°ì´í„°ê°€ ë” ë§ì´ ê¸°ë¡ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì·¨ì†Œìœ¨ ê²°ì¸¡ ì—¬ë¶€\n",
    "df['ì·¨ì†Œìœ¨ê²°ì¸¡'] = df['APV_CE_RAT'].isna().astype(int)\n",
    "\n",
    "cancel_by_delivery = df.groupby('ë°°ë‹¬í™œì„±í™”')['ì·¨ì†Œìœ¨ê²°ì¸¡'].agg(['sum', 'count', 'mean'])\n",
    "cancel_by_delivery.columns = ['ì·¨ì†Œìœ¨ê²°ì¸¡ìˆ˜', 'ì´ìˆ˜', 'ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨']\n",
    "cancel_by_delivery['ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨'] = (cancel_by_delivery['ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨'] * 100).round(2)\n",
    "cancel_by_delivery['ì·¨ì†Œìœ¨ì¡´ì¬ë¹„ìœ¨'] = (100 - cancel_by_delivery['ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨']).round(2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"H4: ë°°ë‹¬ í™œì„±í™” ì—¬ë¶€ë³„ ì·¨ì†Œìœ¨ ë°ì´í„° ì¡´ì¬\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\në°°ë‹¬ í™œì„±í™” ì—¬ë¶€ë³„ ì·¨ì†Œìœ¨ ê²°ì¸¡:\")\n",
    "print(cancel_by_delivery)\n",
    "\n",
    "missing_no_delivery = cancel_by_delivery.loc[0, 'ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨']\n",
    "missing_with_delivery = cancel_by_delivery.loc[1, 'ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨']\n",
    "\n",
    "print(f\"\\në°°ë‹¬ ë¯¸í™œì„±í™”: ì·¨ì†Œìœ¨ ê²°ì¸¡ {missing_no_delivery:.2f}%\")\n",
    "print(f\"ë°°ë‹¬ í™œì„±í™”: ì·¨ì†Œìœ¨ ê²°ì¸¡ {missing_with_delivery:.2f}%\")\n",
    "print(f\"ì°¨ì´: {missing_no_delivery - missing_with_delivery:.2f}%p\")\n",
    "\n",
    "# ì¹´ì´ì œê³± ê²€ì •\n",
    "contingency = pd.crosstab(df['ë°°ë‹¬í™œì„±í™”'], df['ì·¨ì†Œìœ¨ê²°ì¸¡'])\n",
    "chi2, p_val, dof, expected = stats.chi2_contingency(contingency)\n",
    "\n",
    "print(f\"\\nì¹´ì´ì œê³± ê²€ì •:\")\n",
    "print(f\"  chi2: {chi2:.4f}\")\n",
    "print(f\"  p-value: {p_val:.6f}\")\n",
    "\n",
    "if p_val < 0.05 and missing_with_delivery < missing_no_delivery:\n",
    "    result = \"ì±„íƒ\"\n",
    "    interpretation = f\"ë°°ë‹¬ í™œì„±í™”ì‹œ ì·¨ì†Œìœ¨ ê²°ì¸¡ {missing_no_delivery - missing_with_delivery:.2f}%p ê°ì†Œ\"\n",
    "elif p_val < 0.05:\n",
    "    result = \"ê¸°ê° (ì—­ë°©í–¥)\"\n",
    "    interpretation = \"ë°°ë‹¬ í™œì„±í™”ì‹œ ì·¨ì†Œìœ¨ ê²°ì¸¡ ì¦ê°€\"\n",
    "else:\n",
    "    result = \"ê¸°ê°\"\n",
    "    interpretation = \"ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ê²°ë¡ : H4 {result}\")\n",
    "print(f\"í•´ì„: {interpretation}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_labels = ['ë°°ë‹¬ ë¯¸í™œì„±í™”', 'ë°°ë‹¬ í™œì„±í™”']\n",
    "missing_rates = [cancel_by_delivery.loc[0, 'ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨'], \n",
    "                 cancel_by_delivery.loc[1, 'ì·¨ì†Œìœ¨ê²°ì¸¡ë¹„ìœ¨']]\n",
    "exist_rates = [cancel_by_delivery.loc[0, 'ì·¨ì†Œìœ¨ì¡´ì¬ë¹„ìœ¨'], \n",
    "               cancel_by_delivery.loc[1, 'ì·¨ì†Œìœ¨ì¡´ì¬ë¹„ìœ¨']]\n",
    "\n",
    "x = np.arange(len(x_labels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, missing_rates, width, label='ì·¨ì†Œìœ¨ ê²°ì¸¡', color='lightcoral')\n",
    "bars2 = ax.bar(x + width/2, exist_rates, width, label='ì·¨ì†Œìœ¨ ì¡´ì¬', color='lightgreen')\n",
    "\n",
    "ax.set_xlabel('ë°°ë‹¬ í™œì„±í™” ì—¬ë¶€', fontsize=12)\n",
    "ax.set_ylabel('ë¹„ìœ¨ (%)', fontsize=12)\n",
    "ax.set_title('ë°°ë‹¬ í™œì„±í™” ì—¬ë¶€ë³„ ì·¨ì†Œìœ¨ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h5_h11",
   "metadata": {},
   "source": [
    "---\n",
    "## H5-H11: íì—… ì˜ˆì¸¡ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸\n",
    "\n",
    "**ëª©ì **: ë‹¤ì–‘í•œ ë³€ìˆ˜ê°€ íì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„\n",
    "\n",
    "### ê²€ì¦í•  ê°€ì„¤\n",
    "- **H5**: ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ì´ ë†’ì„ìˆ˜ë¡ íì—… í™•ë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤\n",
    "- **H6**: ì·¨ì†Œìœ¨ì´ ë†’ì„ìˆ˜ë¡ íì—… í™•ë¥ ì´ ë†’ì„ ê²ƒì´ë‹¤\n",
    "- **H7**: ê³ ê° ë‹¤ì–‘ì„±ì´ ë†’ì„ìˆ˜ë¡ ìƒì¡´ ê°€ëŠ¥ì„±ì´ ë†’ì„ ê²ƒì´ë‹¤ (Shannon Entropy)\n",
    "- **H9**: ìš´ì˜ê°œì›” ìˆ˜ê°€ ì§§ì„ìˆ˜ë¡ íì—… ê°€ëŠ¥ì„±ì´ ë†’ë‹¤\n",
    "- **H10**: ë™ì¼ ì—…ì¢… ë‚´ í‰ê·  ëŒ€ë¹„ ë§¤ì¶œì´ ë‚®ì„ìˆ˜ë¡ íì—…ìœ„í—˜ì´ ë†’ë‹¤\n",
    "- **H11**: ê±°ì£¼í˜•Â·ì§ì¥í˜•Â·ìœ ë™ì¸êµ¬ ê³ ê° ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ íì—…ìœ„í—˜ì´ ë‚®ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024ë…„ ë°ì´í„°ë§Œ ì‚¬ìš© (ìµœì‹  ë°ì´í„°)\n",
    "df_model = df[df['ì—°ë„'] == '2024'].copy()\n",
    "\n",
    "print(f\"ëª¨ë¸ë§ ë°ì´í„°: {len(df_model):,}ê°œ\")\n",
    "print(f\"íì—…ë¥ : {df_model['íì—…ì—¬ë¶€'].mean()*100:.2f}%\")\n",
    "\n",
    "# H5: ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘\n",
    "df_model['ë°°ë‹¬ë§¤ì¶œë¹„ì¤‘'] = df_model['DLV_SAA_RAT'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "# H6: ì·¨ì†Œìœ¨ (ìˆ«ìí™”)\n",
    "cancel_map = {\n",
    "    '1_ìƒìœ„1êµ¬ê°„': 6, '2_ìƒìœ„2êµ¬ê°„': 5, '3_ìƒìœ„3êµ¬ê°„': 4,\n",
    "    '4_ìƒìœ„4êµ¬ê°„': 3, '5_ìƒìœ„5êµ¬ê°„': 2, '6_ìƒìœ„6êµ¬ê°„(í•˜ìœ„1êµ¬ê°„)': 1\n",
    "}\n",
    "df_model['ì·¨ì†Œìœ¨_ìˆ˜ì¹˜'] = df_model['APV_CE_RAT'].map(cancel_map).fillna(3.5)\n",
    "\n",
    "# H7: ê³ ê° ë‹¤ì–‘ì„± (Shannon Entropy)\n",
    "age_gender_cols = [\n",
    "    'M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT',\n",
    "    'M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT'\n",
    "]\n",
    "\n",
    "def shannon_entropy(row):\n",
    "    \"\"\"Shannon Entropy ê³„ì‚° (ê³ ê° ë‹¤ì–‘ì„± ì§€í‘œ)\"\"\"\n",
    "    values = []\n",
    "    for col in age_gender_cols:\n",
    "        if col in row.index and pd.notna(row[col]):\n",
    "            val = row[col]\n",
    "            if val > 0:\n",
    "                values.append(val)\n",
    "    \n",
    "    if not values:\n",
    "        return 0\n",
    "    \n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    \n",
    "    probs = [v/total for v in values]\n",
    "    entropy = -sum([p * np.log(p) for p in probs if p > 0])\n",
    "    return entropy\n",
    "\n",
    "df_model['ê³ ê°ë‹¤ì–‘ì„±'] = df_model.apply(shannon_entropy, axis=1)\n",
    "\n",
    "# H9: ìš´ì˜ê°œì›”ìˆ˜ (ìˆ«ìí™”)\n",
    "operation_map = {\n",
    "    '1_10%ì´í•˜': 1, '2_10-25%': 2, '3_25-50%': 3,\n",
    "    '4_50-75%': 4, '5_75-90%': 5, '6_90%ì´ˆê³¼(í•˜ìœ„ 10% ì´í•˜)': 6\n",
    "}\n",
    "df_model['ìš´ì˜ê°œì›”ìˆ˜_ìˆ˜ì¹˜'] = df_model['MCT_OPE_MS_CN'].map(operation_map).fillna(3.5)\n",
    "\n",
    "# H10: ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ë¹„ìœ¨\n",
    "df_model['ì—…ì¢…ë‚´ë§¤ì¶œë¹„ìœ¨'] = df_model['M1_SME_RY_SAA_RAT'].fillna(0)\n",
    "\n",
    "# H11: ê±°ì£¼í˜•/ì§ì¥í˜•/ìœ ë™ì¸êµ¬ ê³ ê° ë¹„ìœ¨\n",
    "df_model['ê±°ì£¼í˜•ê³ ê°ë¹„ìœ¨'] = df_model['RC_M1_SHC_RSD_UE_CLN_RAT'].fillna(0)\n",
    "df_model['ì§ì¥í˜•ê³ ê°ë¹„ìœ¨'] = df_model['RC_M1_SHC_WP_UE_CLN_RAT'].fillna(0)\n",
    "df_model['ìœ ë™ì¸êµ¬ê³ ê°ë¹„ìœ¨'] = df_model['RC_M1_SHC_FLP_UE_CLN_RAT'].fillna(0)\n",
    "\n",
    "print(\"\\nâœ“ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logistic_regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”¼ì²˜ ì„ íƒ\n",
    "features = [\n",
    "    'ë§¤ì¶œë“±ê¸‰_ìˆ˜ì¹˜',      # H1\n",
    "    'ë°°ë‹¬ë§¤ì¶œë¹„ì¤‘',       # H5\n",
    "    'ì·¨ì†Œìœ¨_ìˆ˜ì¹˜',        # H6\n",
    "    'ê³ ê°ë‹¤ì–‘ì„±',         # H7\n",
    "    'ìš´ì˜ê°œì›”ìˆ˜_ìˆ˜ì¹˜',    # H9\n",
    "    'ì—…ì¢…ë‚´ë§¤ì¶œë¹„ìœ¨',     # H10\n",
    "    'ê±°ì£¼í˜•ê³ ê°ë¹„ìœ¨',     # H11\n",
    "    'ì§ì¥í˜•ê³ ê°ë¹„ìœ¨',     # H11\n",
    "    'ìœ ë™ì¸êµ¬ê³ ê°ë¹„ìœ¨'    # H11\n",
    "]\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì œê±°\n",
    "df_clean = df_model[features + ['íì—…ì—¬ë¶€']].dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ë§\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nëª¨ë¸ë§ ë°ì´í„°: {len(df_clean):,}ê°œ\")\n",
    "print(f\"íì—…ë¥ : {df_clean['íì—…ì—¬ë¶€'].mean()*100:.2f}%\")\n",
    "print(f\"íì—… ê±´ìˆ˜: {df_clean['íì—…ì—¬ë¶€'].sum():,}ê°œ\")\n",
    "\n",
    "X = df_clean[features]\n",
    "y = df_clean['íì—…ì—¬ë¶€']\n",
    "\n",
    "# í‘œì¤€í™”\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nëª¨ë¸ ì„±ëŠ¥:\")\n",
    "print(f\"  Train ì •í™•ë„: {train_acc*100:.2f}%\")\n",
    "print(f\"  Test ì •í™•ë„: {test_acc*100:.2f}%\")\n",
    "print(f\"  AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "coef_df = pd.DataFrame({\n",
    "    'ë³€ìˆ˜': features,\n",
    "    'ê³„ìˆ˜': model.coef_[0]\n",
    "}).sort_values('ê³„ìˆ˜', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\në³€ìˆ˜ ì¤‘ìš”ë„ (ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜):\")\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "colors = ['red' if x > 0 else 'blue' for x in coef_df['ê³„ìˆ˜']]\n",
    "axes[0, 0].barh(range(len(coef_df)), coef_df['ê³„ìˆ˜'], color=colors, alpha=0.7)\n",
    "axes[0, 0].set_yticks(range(len(coef_df)))\n",
    "axes[0, 0].set_yticklabels(coef_df['ë³€ìˆ˜'])\n",
    "axes[0, 0].set_xlabel('ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜', fontsize=12)\n",
    "axes[0, 0].set_title('ë³€ìˆ˜ ì¤‘ìš”ë„ (ê³„ìˆ˜)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.4f}')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "axes[0, 1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0, 1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0, 1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n",
    "axes[1, 0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Actual', fontsize=12)\n",
    "axes[1, 0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticklabels(['ë¹„íì—…', 'íì—…'])\n",
    "axes[1, 0].set_yticklabels(['ë¹„íì—…', 'íì—…'])\n",
    "\n",
    "# 4. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬\n",
    "axes[1, 1].hist([y_pred_proba[y_test==0], y_pred_proba[y_test==1]], \n",
    "                bins=30, label=['ì‹¤ì œ ë¹„íì—…', 'ì‹¤ì œ íì—…'], alpha=0.7)\n",
    "axes[1, 1].set_xlabel('íì—… ì˜ˆì¸¡ í™•ë¥ ', fontsize=12)\n",
    "axes[1, 1].set_ylabel('ë¹ˆë„', fontsize=12)\n",
    "axes[1, 1].set_title('íì—… ì˜ˆì¸¡ í™•ë¥  ë¶„í¬', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hypothesis_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°€ì„¤ë³„ ê²€ì¦ ê²°ê³¼\n",
    "coef_dict = dict(zip(features, model.coef_[0]))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ê°€ì„¤ë³„ ê²€ì¦ ê²°ê³¼ (ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜ ê¸°ë°˜)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "# H5\n",
    "print(f\"\\nH5 (ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘): ê³„ìˆ˜ = {coef_dict['ë°°ë‹¬ë§¤ì¶œë¹„ì¤‘']:.4f}\")\n",
    "if coef_dict['ë°°ë‹¬ë§¤ì¶œë¹„ì¤‘'] < -0.01:\n",
    "    h5_result = \"ì±„íƒ\"\n",
    "    h5_interpretation = \"ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ â†‘ â†’ íì—… í™•ë¥  â†“\"\n",
    "elif coef_dict['ë°°ë‹¬ë§¤ì¶œë¹„ì¤‘'] > 0.01:\n",
    "    h5_result = \"ê¸°ê° (ì—­ë°©í–¥)\"\n",
    "    h5_interpretation = \"ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ â†‘ â†’ íì—… í™•ë¥  â†‘ (ê³¼ë„í•œ ì˜ì¡´ ìœ„í—˜)\"\n",
    "else:\n",
    "    h5_result = \"ê¸°ê°\"\n",
    "    h5_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ\"\n",
    "print(f\"  ê²°ë¡ : {h5_result}\")\n",
    "print(f\"  í•´ì„: {h5_interpretation}\")\n",
    "results.append(['H5', 'ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘â†‘ â†’ íì—…â†“', h5_result, h5_interpretation])\n",
    "\n",
    "# H6\n",
    "print(f\"\\nH6 (ì·¨ì†Œìœ¨): ê³„ìˆ˜ = {coef_dict['ì·¨ì†Œìœ¨_ìˆ˜ì¹˜']:.4f}\")\n",
    "if coef_dict['ì·¨ì†Œìœ¨_ìˆ˜ì¹˜'] > 0.01:\n",
    "    h6_result = \"ì±„íƒ\"\n",
    "    h6_interpretation = \"ì·¨ì†Œìœ¨ â†‘ â†’ íì—… í™•ë¥  â†‘\"\n",
    "else:\n",
    "    h6_result = \"ê¸°ê°\"\n",
    "    h6_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ\"\n",
    "print(f\"  ê²°ë¡ : {h6_result}\")\n",
    "print(f\"  í•´ì„: {h6_interpretation}\")\n",
    "results.append(['H6', 'ì·¨ì†Œìœ¨â†‘ â†’ íì—…â†‘', h6_result, h6_interpretation])\n",
    "\n",
    "# H7\n",
    "print(f\"\\nH7 (ê³ ê° ë‹¤ì–‘ì„±): ê³„ìˆ˜ = {coef_dict['ê³ ê°ë‹¤ì–‘ì„±']:.4f}\")\n",
    "if coef_dict['ê³ ê°ë‹¤ì–‘ì„±'] < -0.01:\n",
    "    h7_result = \"ì±„íƒ\"\n",
    "    h7_interpretation = \"ê³ ê° ë‹¤ì–‘ì„± â†‘ â†’ íì—… í™•ë¥  â†“\"\n",
    "else:\n",
    "    h7_result = \"ê¸°ê°\"\n",
    "    h7_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ\"\n",
    "print(f\"  ê²°ë¡ : {h7_result}\")\n",
    "print(f\"  í•´ì„: {h7_interpretation}\")\n",
    "results.append(['H7', 'ê³ ê°ë‹¤ì–‘ì„±â†‘ â†’ íì—…â†“', h7_result, h7_interpretation])\n",
    "\n",
    "# H9\n",
    "print(f\"\\nH9 (ìš´ì˜ê°œì›”ìˆ˜): ê³„ìˆ˜ = {coef_dict['ìš´ì˜ê°œì›”ìˆ˜_ìˆ˜ì¹˜']:.4f}\")\n",
    "if coef_dict['ìš´ì˜ê°œì›”ìˆ˜_ìˆ˜ì¹˜'] < -0.01:\n",
    "    h9_result = \"ì±„íƒ\"\n",
    "    h9_interpretation = \"ìš´ì˜ê°œì›”ìˆ˜ â†‘ â†’ íì—… í™•ë¥  â†“\"\n",
    "else:\n",
    "    h9_result = \"ê¸°ê°\"\n",
    "    h9_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ (ë˜ëŠ” ì—­ë°©í–¥)\"\n",
    "print(f\"  ê²°ë¡ : {h9_result}\")\n",
    "print(f\"  í•´ì„: {h9_interpretation}\")\n",
    "results.append(['H9', 'ìš´ì˜ê°œì›”ìˆ˜â†“ â†’ íì—…â†‘', h9_result, h9_interpretation])\n",
    "\n",
    "# H10\n",
    "print(f\"\\nH10 (ì—…ì¢…ë‚´ ë§¤ì¶œë¹„ìœ¨): ê³„ìˆ˜ = {coef_dict['ì—…ì¢…ë‚´ë§¤ì¶œë¹„ìœ¨']:.4f}\")\n",
    "if coef_dict['ì—…ì¢…ë‚´ë§¤ì¶œë¹„ìœ¨'] < -0.01:\n",
    "    h10_result = \"ì±„íƒ\"\n",
    "    h10_interpretation = \"ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œ â†‘ â†’ íì—… í™•ë¥  â†“\"\n",
    "else:\n",
    "    h10_result = \"ê¸°ê°\"\n",
    "    h10_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ\"\n",
    "print(f\"  ê²°ë¡ : {h10_result}\")\n",
    "print(f\"  í•´ì„: {h10_interpretation}\")\n",
    "results.append(['H10', 'ì—…ì¢…ë‚´ë§¤ì¶œâ†“ â†’ íì—…â†‘', h10_result, h10_interpretation])\n",
    "\n",
    "# H11\n",
    "print(f\"\\nH11 (ê³ ê° ìœ í˜•):\")\n",
    "print(f\"  ê±°ì£¼í˜•: {coef_dict['ê±°ì£¼í˜•ê³ ê°ë¹„ìœ¨']:.4f}\")\n",
    "print(f\"  ì§ì¥í˜•: {coef_dict['ì§ì¥í˜•ê³ ê°ë¹„ìœ¨']:.4f}\")\n",
    "print(f\"  ìœ ë™ì¸êµ¬: {coef_dict['ìœ ë™ì¸êµ¬ê³ ê°ë¹„ìœ¨']:.4f}\")\n",
    "\n",
    "if any(coef_dict[col] < -0.01 for col in ['ê±°ì£¼í˜•ê³ ê°ë¹„ìœ¨', 'ì§ì¥í˜•ê³ ê°ë¹„ìœ¨', 'ìœ ë™ì¸êµ¬ê³ ê°ë¹„ìœ¨']):\n",
    "    h11_result = \"ì±„íƒ\"\n",
    "    h11_interpretation = \"íŠ¹ì • ê³ ê° ìœ í˜• ë¹„ìœ¨ â†‘ â†’ íì—… í™•ë¥  â†“\"\n",
    "else:\n",
    "    h11_result = \"ê¸°ê°\"\n",
    "    h11_interpretation = \"ìœ ì˜í•œ ì˜í–¥ ì—†ìŒ\"\n",
    "print(f\"  ê²°ë¡ : {h11_result}\")\n",
    "print(f\"  í•´ì„: {h11_interpretation}\")\n",
    "results.append(['H11', 'ê³ ê°ìœ í˜•ë¹„ìœ¨â†‘ â†’ íì—…â†“', h11_result, h11_interpretation])\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”\n",
    "print(f\"\\n{'='*60}\")\n",
    "results_df = pd.DataFrame(results, columns=['ê°€ì„¤', 'ë‚´ìš©', 'ê²°ê³¼', 'í•´ì„'])\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_h8",
   "metadata": {},
   "source": [
    "---\n",
    "## H8: ìƒê¶Œë³„ íì—…ë¥  ì°¨ì´\n",
    "\n",
    "**ê°€ì„¤**: ìƒê¶Œ(ì„±ìˆ˜Â·ì™•ì‹­ë¦¬Â·ë§ˆì¥ ë“±)ì— ë”°ë¼ íì—…ë¥ ì˜ ì°¨ì´ê°€ ìœ ì˜í•˜ë‹¤  \n",
    "**ê²€ì¦**: ì¹´ì´ì œê³± ê²€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h8_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒê¶Œë³„ íì—…ë¥ \n",
    "district_closure = df.groupby('HPSN_MCT_BZN_CD_NM')['íì—…ì—¬ë¶€'].agg(['sum', 'count', 'mean'])\n",
    "district_closure.columns = ['íì—…ìˆ˜', 'ì´ê°€ë§¹ì ìˆ˜', 'íì—…ë¥ ']\n",
    "district_closure['íì—…ë¥ '] = (district_closure['íì—…ë¥ '] * 100).round(2)\n",
    "district_closure = district_closure.sort_values('íì—…ë¥ ', ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"H8: ìƒê¶Œë³„ íì—…ë¥  ì°¨ì´\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nìƒê¶Œë³„ íì—…ë¥  (ì „ì²´):\")\n",
    "print(district_closure.to_string())\n",
    "\n",
    "# ì¹´ì´ì œê³± ê²€ì •\n",
    "contingency = pd.crosstab(df['HPSN_MCT_BZN_CD_NM'], df['íì—…ì—¬ë¶€'])\n",
    "chi2, p_val, dof, expected = stats.chi2_contingency(contingency)\n",
    "\n",
    "print(f\"\\nì¹´ì´ì œê³± ê²€ì •:\")\n",
    "print(f\"  chi2: {chi2:.4f}\")\n",
    "print(f\"  p-value: {p_val:.6f}\")\n",
    "print(f\"  ììœ ë„: {dof}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    result = \"ì±„íƒ\"\n",
    "    interpretation = \"ìƒê¶Œë³„ íì—…ë¥ ì— ìœ ì˜í•œ ì°¨ì´ ì¡´ì¬\"\n",
    "else:\n",
    "    result = \"ê¸°ê°\"\n",
    "    interpretation = \"ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ê²°ë¡ : H8 {result}\")\n",
    "print(f\"í•´ì„: {interpretation}\")\n",
    "print(f\"\\nìµœê³  ìœ„í—˜ ìƒê¶Œ: {district_closure.index[0]} ({district_closure.iloc[0]['íì—…ë¥ ']:.2f}%)\")\n",
    "print(f\"ìµœì € ìœ„í—˜ ìƒê¶Œ: {district_closure.index[-1]} ({district_closure.iloc[-1]['íì—…ë¥ ']:.2f}%)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h8_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ìƒê¶Œë³„ íì—…ë¥ \n",
    "axes[0].barh(range(len(district_closure)), district_closure['íì—…ë¥ '], color='coral', alpha=0.7)\n",
    "axes[0].set_yticks(range(len(district_closure)))\n",
    "axes[0].set_yticklabels(district_closure.index)\n",
    "axes[0].set_xlabel('íì—…ë¥  (%)', fontsize=12)\n",
    "axes[0].set_title('ìƒê¶Œë³„ íì—…ë¥ ', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# ìƒê¶Œë³„ ê°€ë§¹ì  ìˆ˜ vs íì—…ë¥  ì‚°ì ë„\n",
    "axes[1].scatter(district_closure['ì´ê°€ë§¹ì ìˆ˜'], district_closure['íì—…ë¥ '], \n",
    "                s=100, alpha=0.6, c=district_closure['íì—…ë¥ '], cmap='Reds')\n",
    "for idx, row in district_closure.iterrows():\n",
    "    axes[1].annotate(idx, (row['ì´ê°€ë§¹ì ìˆ˜'], row['íì—…ë¥ ']), \n",
    "                    fontsize=9, alpha=0.7, ha='right')\n",
    "axes[1].set_xlabel('ì´ ê°€ë§¹ì  ìˆ˜', fontsize=12)\n",
    "axes[1].set_ylabel('íì—…ë¥  (%)', fontsize=12)\n",
    "axes[1].set_title('ìƒê¶Œë³„ ê°€ë§¹ì  ìˆ˜ vs íì—…ë¥ ', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š 11ê°œ ê°€ì„¤ ê²€ì¦ ê²°ê³¼ ì¢…í•©\n",
    "\n",
    "### âœ… ì±„íƒëœ ê°€ì„¤ (7ê°œ)\n",
    "\n",
    "| ê°€ì„¤ | ë‚´ìš© | ì£¼ìš” ê²°ê³¼ |\n",
    "|------|------|----------|\n",
    "| **H2** | 2023 Q1 ëŒ€ë¹„ 2024 Q4 ë°°ë‹¬ ì§€í‘œ ì¦ê°€ | ë°°ë‹¬ í™œì„±í™” +0.75%p, í‰ê·  ë°°ë‹¬ë§¤ì¶œ +4.48%p |\n",
    "| **H3** | 2023â†’2024ë…„ ë°°ë‹¬ ë°ì´í„° ì¡´ì¬ ë¹„ìœ¨ ì¦ê°€ | 29.06% â†’ 29.72% (+0.66%p) |\n",
    "| **H4** | ë°°ë‹¬ í™œì„±í™”ì‹œ ì·¨ì†Œìœ¨ ê²°ì¸¡ ê°ì†Œ | 10.17% â†’ 1.63% (-8.54%p) |\n",
    "| **H5** | ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ê³¼ íì—… (ì—­ë°©í–¥) | ê³„ìˆ˜ +0.171 (ê³¼ë„í•œ ë°°ë‹¬ ì˜ì¡´ ìœ„í—˜) |\n",
    "| **H8** | ìƒê¶Œë³„ íì—…ë¥  ì°¨ì´ | ì‹ ê¸ˆí˜¸ 4.47% vs ë§ˆì¥ë™ 1.95% |\n",
    "| **H10** | ì—…ì¢… ë‚´ ë§¤ì¶œ ë¹„ìœ¨ | ê³„ìˆ˜ -0.111 (ê²½ìŸë ¥â†‘ â†’ íì—…â†“) |\n",
    "| **H11** | ê³ ê° ìœ í˜• ë¹„ìœ¨ | ê³„ìˆ˜ -0.061 (ê³ ê°ê¸°ë°˜â†‘ â†’ íì—…â†“) |\n",
    "\n",
    "### âŒ ê¸°ê°ëœ ê°€ì„¤ (4ê°œ)\n",
    "\n",
    "| ê°€ì„¤ | ë‚´ìš© | ì´ìœ  |\n",
    "|------|------|------|\n",
    "| **H1** | íì—… ê°€ë§¹ì  ë§¤ì¶œë“±ê¸‰ ë‚®ìŒ | p-value = 0.138 (ìœ ì˜í•˜ì§€ ì•ŠìŒ) |\n",
    "| **H6** | ì·¨ì†Œìœ¨â†‘ â†’ íì—…â†‘ | ê³„ìˆ˜ â‰ˆ 0 (ì˜í–¥ ë¯¸ë¯¸) |\n",
    "| **H7** | ê³ ê° ë‹¤ì–‘ì„±â†‘ â†’ íì—…â†“ | ê³„ìˆ˜ â‰ˆ 0 (ì˜í–¥ ë¯¸ë¯¸) |\n",
    "| **H9** | ìš´ì˜ê°œì›”ìˆ˜â†“ â†’ íì—…â†‘ | ê³„ìˆ˜ +0.361 (ì˜ˆìƒê³¼ ë°˜ëŒ€) |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "### 1. ë°°ë‹¬ ì˜ì¡´ì˜ ì–‘ë©´ì„±\n",
    "- âœ… **ë°°ë‹¬ ì„œë¹„ìŠ¤ëŠ” í™•ì‚° ì¤‘** (H2, H3 ì±„íƒ)\n",
    "  - ë•¡ê²¨ìš” ì•± íš¨ê³¼ë¡œ ë°°ë‹¬ í™œì„±í™” ì¦ê°€\n",
    "  - í‰ê·  ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨ 4.48%p ì¦ê°€\n",
    "\n",
    "- âš ï¸ **ê³¼ë„í•œ ë°°ë‹¬ ì˜ì¡´ì€ íì—… ìœ„í—˜** (H5 ì—­ë°©í–¥ ì±„íƒ)\n",
    "  - ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ì´ ë†’ì„ìˆ˜ë¡ íì—… í™•ë¥  ì¦ê°€ (ê³„ìˆ˜ +0.171)\n",
    "  - ë°°ë‹¬ ìˆ˜ìˆ˜ë£Œ, í”Œë«í¼ ì˜ì¡´ë„ë¡œ ì¸í•œ ê²½ì˜ ë¶ˆì•ˆì •\n",
    "\n",
    "### 2. ì·¨ì†Œìœ¨ ë°ì´í„°ì˜ ì˜ë¯¸\n",
    "- ë°°ë‹¬ í™œì„±í™” ê°€ë§¹ì ì˜ ì·¨ì†Œìœ¨ ë°ì´í„°ê°€ 8.54%p ë” ë§ìŒ\n",
    "- **ë°°ë‹¬ ì£¼ë¬¸ì—ì„œ ì·¨ì†Œê°€ ë” ë¹ˆë²ˆí•˜ê²Œ ë°œìƒ**\n",
    "- ëŒ€ê¸°ì‹œê°„, ê±°ë¦¬ ë¬¸ì œë¡œ ì¸í•œ ì·¨ì†Œ ì‹œ **ëŒ€ì²´ ê°€ë§¹ì  ì¶”ì²œ í•„ìš”**\n",
    "\n",
    "### 3. ìƒê¶Œë³„ ìœ„í—˜ë„\n",
    "- ê³ ìœ„í—˜ ìƒê¶Œ: **ì‹ ê¸ˆí˜¸ (4.47%)**, ì¥í•œí‰ìë™ì°¨ (4.20%)\n",
    "- ì €ìœ„í—˜ ìƒê¶Œ: **ë§ˆì¥ë™ (1.95%)**, ëšì„¬ (1.99%)\n",
    "- ìƒê¶Œë³„ ë§ì¶¤í˜• ì§€ì› í•„ìš”\n",
    "\n",
    "### 4. íì—… ìœ„í—˜ ìš”ì¸ ìš°ì„ ìˆœìœ„\n",
    "1. **ìš´ì˜ê°œì›”ìˆ˜** (ê³„ìˆ˜ 0.361) - ë°ì´í„° í•´ì„ ì£¼ì˜ í•„ìš”\n",
    "2. **ë°°ë‹¬ë§¤ì¶œ ì˜ì¡´ë„** (ê³„ìˆ˜ 0.171) - ê³¼ë„í•œ ì˜ì¡´ ìœ„í—˜\n",
    "3. **ë§¤ì¶œë“±ê¸‰** (ê³„ìˆ˜ -0.135) - ë‚®ì„ìˆ˜ë¡ ìœ„í—˜\n",
    "4. **ì—…ì¢… ë‚´ ê²½ìŸë ¥** (ê³„ìˆ˜ -0.111) - ë‚®ì„ìˆ˜ë¡ ìœ„í—˜\n",
    "5. **ê³ ê° ê¸°ë°˜** (ê³„ìˆ˜ -0.061) - ë¶€ì¡±í• ìˆ˜ë¡ ìœ„í—˜\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì •ì±… ì œì•ˆ\n",
    "\n",
    "### 1. ë°°ë‹¬ ì˜ì¡´ë„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ\n",
    "- ë°°ë‹¬ë§¤ì¶œ ë¹„ì¤‘ > 40% ê°€ë§¹ì  ê²½ê³ \n",
    "- ì˜¤í”„ë¼ì¸ ë§¤ì¶œ í™œì„±í™” ì§€ì› (ì¿ í°, ì´ë²¤íŠ¸)\n",
    "- ë•¡ê²¨ìš” ì•± ìˆ˜ìˆ˜ë£Œ í˜œíƒ + ê²½ì˜ ì»¨ì„¤íŒ…\n",
    "\n",
    "### 2. ì·¨ì†Œ ë°©ì§€ ëŒ€ì²´ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "- ì·¨ì†Œ ì‹œ ìœ ì‚¬ ì—…ì¢… + ê°€ê¹Œìš´ ê±°ë¦¬ ê°€ë§¹ì  ìë™ ì¶”ì²œ\n",
    "- ì¥ê±°ë¦¬ ì£¼ë¬¸ â†’ ë‹¨ê±°ë¦¬ ëŒ€ì²´ ê°€ë§¹ì  ìš°ì„  ë…¸ì¶œ\n",
    "- ëŒ€ê¸°ì‹œê°„ ê¸´ ê°€ë§¹ì  â†’ ë¹ ë¥¸ ë°°ë‹¬ ê°€ëŠ¥ ê°€ë§¹ì  ì—°ê²°\n",
    "\n",
    "### 3. ê³ ìœ„í—˜ ìƒê¶Œ ì§‘ì¤‘ ì§€ì›\n",
    "- ì‹ ê¸ˆí˜¸, ì¥í•œí‰ìë™ì°¨ ë“± ê³ ìœ„í—˜ ìƒê¶Œ ëª¨ë‹ˆí„°ë§\n",
    "- ìƒê¶Œë³„ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ë° ì»¨ì„¤íŒ…\n",
    "- ì§€ì—­ íŠ¹ì„±ì— ë§ëŠ” ë©”ë‰´ ê°œë°œ ì§€ì›\n",
    "\n",
    "### 4. ì¡°ê¸°ê²½ë³´ ê°€ë§¹ì  ìš°ì„  ë…¸ì¶œ ê´‘ê³ \n",
    "- íì—… ìœ„í—˜ ê°€ë§¹ì ì— ì €ë ´í•œ ì•± ë‚´ ê´‘ê³  ì œê³µ\n",
    "- ì£¼ë¬¸ ê³¨ê³ ë£¨ ë¶„ì‚° â†’ ë§¤ì¶œ ì•ˆì •í™”\n",
    "- Win-Win: ê°€ë§¹ì  ë§¤ì¶œâ†‘ + í”Œë«í¼ ìˆ˜ìµâ†‘\n",
    "\n",
    "### 5. ê²½ìŸë ¥ ê°•í™” í”„ë¡œê·¸ë¨\n",
    "- ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œ í•˜ìœ„ 30% ê°€ë§¹ì  ì§€ì›\n",
    "- ë©”ë‰´ ê°œë°œ, ê³ ê° ì„œë¹„ìŠ¤ êµìœ¡\n",
    "- ìš°ìˆ˜ ì‚¬ë¡€ ê³µìœ  ë° ë²¤ì¹˜ë§ˆí‚¹\n",
    "\n",
    "---\n",
    "\n",
    "**ë¶„ì„ ì™„ë£Œì¼**: 2025-01-11  \n",
    "**ë°ì´í„° ê¸°ê°„**: 2023.01 ~ 2024.12 (24ê°œì›”)  \n",
    "**ì´ ë°ì´í„°**: 86,590ê°œ  \n",
    "**íì—…ë¥ **: 2.70%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
