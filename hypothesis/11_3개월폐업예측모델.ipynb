{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 3개월 폐업 예측 모델\n",
    "\n",
    "## 목적\n",
    "- reference.ipynb 섹션 4-4 방법론을 적용하여 3개월 내 폐업 예측 모델 구축\n",
    "- 3가지 모델(LogisticRegression, HistGradientBoosting, RandomForest) 비교\n",
    "- ROC-AUC, PR-AUC, F1 Score로 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    average_precision_score, \n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "print(\"라이브러리 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 타깃 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 형태: (86263, 188)\n",
      "클러스터링 결과 형태: (4325, 4)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로\n",
    "data_path = \"/Users/yeong-gwang/Documents/배움 오전 1.38.42/외부/공모전/빅콘테스트/Project/work/ver3_/1009/빅콘테스트_전체병합데이터_20251008.csv\"\n",
    "result_dir = \"/Users/yeong-gwang/Documents/배움 오전 1.38.42/외부/공모전/빅콘테스트/Project/work/ver3_/1012/result/3_가설1분석\"\n",
    "\n",
    "# 전체 데이터 로드\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"전체 데이터 형태: {df.shape}\")\n",
    "\n",
    "# 클러스터링 결과 로드\n",
    "cluster_result = pd.read_csv(f\"{result_dir}/클러스터링_결과_완전판.csv\")\n",
    "print(f\"클러스터링 결과 형태: {cluster_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[타깃 변수 분포]\n",
      "y_close_3m\n",
      "0    88946\n",
      "1      457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "폐업 비율: 0.51%\n"
     ]
    }
   ],
   "source": [
    "# 타깃 변수 생성: y_close_3m\n",
    "# 상태가 'D-3m'이면 1, 아니면 0\n",
    "\n",
    "df_model = cluster_result.merge(df, on='가맹점구분번호', how='left')\n",
    "\n",
    "# 타깃 변수 (D-3m만 1, 나머지 0)\n",
    "df_model['y_close_3m'] = (df_model['상태'] == 'D-3m').astype(int)\n",
    "\n",
    "print(\"\\n[타깃 변수 분포]\")\n",
    "print(df_model['y_close_3m'].value_counts())\n",
    "print(f\"\\n폐업 비율: {df_model['y_close_3m'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 피처 선택 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[선택된 피처 개수]: 168\n",
      "\n",
      "[상위 10개 피처]:\n",
      "1. CPI_품목_월세\n",
      "2. 동일 업종 매출건수 비율\n",
      "3. CPI_목적_음식및숙박_숙박서비스\n",
      "4. CPI_목적_기타상품및서비스_미용용품및미용서비스\n",
      "5. CPI_품목상세_서비스_공공서비스\n",
      "6. CPI_품목_국산쇠고기\n",
      "7. CPI_품목_치과진료비\n",
      "8. 식료품_지출_총금액\n",
      "9. CPI_품목_휘발유\n",
      "10. 생활물가지수\n"
     ]
    }
   ],
   "source": [
    "# 제외할 컬럼 (식별자, 타깃, 날짜 등)\n",
    "exclude_cols = {\n",
    "    '가맹점구분번호', '기준년월', '기준연월', '기준분기', '개설일', '폐업일',\n",
    "    '상태', 'y_close_3m', 'cluster',\n",
    "    '좌표정보(X)', '좌표정보(Y)', '상권_코드', '상권_코드_명'\n",
    "}\n",
    "\n",
    "# 사용 가능한 피처 선택\n",
    "all_cols = set(df_model.columns)\n",
    "feature_cols = list(all_cols - exclude_cols)\n",
    "\n",
    "# 수치형 피처만 선택\n",
    "numeric_features = []\n",
    "for col in feature_cols:\n",
    "    if col in df_model.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_model[col]):\n",
    "            numeric_features.append(col)\n",
    "\n",
    "print(f\"\\n[선택된 피처 개수]: {len(numeric_features)}\")\n",
    "print(f\"\\n[상위 10개 피처]:\")\n",
    "for i, col in enumerate(numeric_features[:10], 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 데이터 형태: X=(89403, 168), y=(89403,)\n",
      "결측치 개수: 0\n"
     ]
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "X = df_model[numeric_features].copy()\n",
    "y = df_model['y_close_3m'].copy()\n",
    "\n",
    "# 결측치를 중앙값으로 대치\n",
    "for col in X.columns:\n",
    "    if X[col].isna().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# 무한대 값 처리\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "for col in X.columns:\n",
    "    if X[col].isna().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"\\n최종 데이터 형태: X={X.shape}, y={y.shape}\")\n",
    "print(f\"결측치 개수: {X.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: (71522, 168), 폐업률=0.51%\n",
      "Test set: (17881, 168), 폐업률=0.51%\n"
     ]
    }
   ],
   "source": [
    "# 80:20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, 폐업률={y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test set: {X_test.shape}, 폐업률={y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 구축 (reference.ipynb 방법론)\n",
    "\n",
    "### 3가지 모델:\n",
    "1. **LogisticRegression**: 베이스라인\n",
    "2. **HistGradientBoostingClassifier**: 권장 모델\n",
    "3. **RandomForestClassifier**: 랜덤 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 불균형 비율 (0:1) = 194.4:1\n",
      "전처리 파이프라인 및 오버샘플링 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 불균형 비율 계산\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"클래스 불균형 비율 (0:1) = {pos_weight:.1f}:1\")\n",
    "\n",
    "# 전처리 파이프라인 (스케일링)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 수동 오버샘플링 함수\n",
    "def manual_oversample(X, y, random_state=42):\n",
    "    \"\"\"소수 클래스를 다수 클래스와 같은 수로 오버샘플링\"\"\"\n",
    "    # 클래스별로 분리\n",
    "    X_maj = X[y == 0]\n",
    "    X_min = X[y == 1]\n",
    "    y_maj = y[y == 0]\n",
    "    y_min = y[y == 1]\n",
    "    \n",
    "    # 소수 클래스 오버샘플링\n",
    "    X_min_upsampled = resample(X_min, \n",
    "                                replace=True,\n",
    "                                n_samples=len(X_maj),\n",
    "                                random_state=random_state)\n",
    "    y_min_upsampled = np.ones(len(X_maj), dtype=int)\n",
    "    \n",
    "    # 합치기\n",
    "    X_resampled = pd.concat([X_maj, pd.DataFrame(X_min_upsampled, columns=X_min.columns)])\n",
    "    y_resampled = np.concatenate([y_maj, y_min_upsampled])\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "print(\"전처리 파이프라인 및 오버샘플링 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[모델 정의 완료]\n",
      "- logit\n",
      "- hgb\n",
      "- rf_bal\n"
     ]
    }
   ],
   "source": [
    "# 1) Logistic Regression (베이스라인)\n",
    "logit = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) HistGradientBoosting (권장 모델)\n",
    "hgb = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=31,\n",
    "        min_samples_leaf=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3) RandomForest + 수동 오버샘플링\n",
    "# 오버샘플링은 학습 시 직접 적용\n",
    "rf_clf = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'logit': logit,\n",
    "    'hgb': hgb,\n",
    "    'rf_bal': rf_clf  # 오버샘플링은 학습 시 적용\n",
    "}\n",
    "\n",
    "print(\"\\n[모델 정의 완료]\")\n",
    "for name in models:\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[logit] 학습 시작...\n",
      "============================================================\n",
      "\n",
      "[logit] ROC-AUC=1.000  PR-AUC=1.000  F1@0.5=1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000     17790\n",
      "           1      1.000     1.000     1.000        91\n",
      "\n",
      "    accuracy                          1.000     17881\n",
      "   macro avg      1.000     1.000     1.000     17881\n",
      "weighted avg      1.000     1.000     1.000     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[hgb] 학습 시작...\n",
      "============================================================\n",
      "\n",
      "[hgb] ROC-AUC=1.000  PR-AUC=1.000  F1@0.5=1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000     17790\n",
      "           1      1.000     1.000     1.000        91\n",
      "\n",
      "    accuracy                          1.000     17881\n",
      "   macro avg      1.000     1.000     1.000     17881\n",
      "weighted avg      1.000     1.000     1.000     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[rf_bal] 학습 시작...\n",
      "============================================================\n",
      "  오버샘플링 적용 중...\n",
      "  오버샘플링 후: (142312, 168), 폐업률=50.00%\n",
      "\n",
      "[rf_bal] ROC-AUC=1.000  PR-AUC=0.993  F1@0.5=0.829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.998     0.999     17790\n",
      "           1      0.714     0.989     0.829        91\n",
      "\n",
      "    accuracy                          0.998     17881\n",
      "   macro avg      0.857     0.993     0.914     17881\n",
      "weighted avg      0.998     0.998     0.998     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[모든 모델 학습 완료]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[{name}] 학습 시작...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # rf_bal의 경우 오버샘플링 적용\n",
    "    if name == 'rf_bal':\n",
    "        print(\"  오버샘플링 적용 중...\")\n",
    "        X_train_balanced, y_train_balanced = manual_oversample(X_train, y_train, random_state=42)\n",
    "        print(f\"  오버샘플링 후: {X_train_balanced.shape}, 폐업률={y_train_balanced.mean()*100:.2f}%\")\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 확률 예측\n",
    "    if hasattr(model[-1], 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'ROC-AUC': roc,\n",
    "        'PR-AUC': pr,\n",
    "        'F1@0.5': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[{name}] ROC-AUC={roc:.3f}  PR-AUC={pr:.3f}  F1@0.5={f1:.3f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[모든 모델 학습 완료]\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[최종 성능 비교]\n",
      "============================================================\n",
      "        ROC-AUC  PR-AUC  F1@0.5\n",
      "logit       1.0   1.000   1.000\n",
      "hgb         1.0   1.000   1.000\n",
      "rf_bal      1.0   0.993   0.829\n",
      "\n",
      "🏆 Best Model (ROC-AUC 기준): logit (ROC-AUC=1.000)\n"
     ]
    }
   ],
   "source": [
    "# 결과 DataFrame 생성\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[최종 성능 비교]\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Best model 선택\n",
    "best_name = results_df.index[0]\n",
    "best_score = results_df.loc[best_name, 'ROC-AUC']\n",
    "\n",
    "print(f\"\\n🏆 Best Model (ROC-AUC 기준): {best_name} (ROC-AUC={best_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 결과 저장 완료: /Users/yeong-gwang/Documents/배움 오전 1.38.42/외부/공모전/빅콘테스트/Project/work/ver3_/1012/result/3_가설1분석/11_모델성능_비교결과.csv\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장\n",
    "results_df.to_csv(f\"{result_dir}/11_모델성능_비교결과.csv\", encoding='utf-8-sig')\n",
    "print(f\"\\n✅ 결과 저장 완료: {result_dir}/11_모델성능_비교결과.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 해석\n",
    "\n",
    "**실제 실행 결과를 바탕으로**:\n",
    "- 3가지 모델의 성능을 직접 비교\n",
    "- ROC-AUC, PR-AUC, F1 Score로 평가\n",
    "- Best Model을 선정하여 보고서에 반영"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
