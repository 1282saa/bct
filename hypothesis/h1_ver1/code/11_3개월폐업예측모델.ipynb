{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 3ê°œì›” íì—… ì˜ˆì¸¡ ëª¨ë¸\n",
    "\n",
    "## ëª©ì \n",
    "- reference.ipynb ì„¹ì…˜ 4-4 ë°©ë²•ë¡ ì„ ì ìš©í•˜ì—¬ 3ê°œì›” ë‚´ íì—… ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•\n",
    "- 3ê°€ì§€ ëª¨ë¸(LogisticRegression, HistGradientBoosting, RandomForest) ë¹„êµ\n",
    "- ROC-AUC, PR-AUC, F1 Scoreë¡œ ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    average_precision_score, \n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¡œë“œ ë° íƒ€ê¹ƒ ë³€ìˆ˜ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„° í˜•íƒœ: (86263, 188)\n",
      "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í˜•íƒœ: (4325, 4)\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = \"/Users/yeong-gwang/Documents/ë°°ì›€ ì˜¤ì „ 1.38.42/ì™¸ë¶€/ê³µëª¨ì „/ë¹…ì½˜í…ŒìŠ¤íŠ¸/Project/work/ver3_/1009/ë¹…ì½˜í…ŒìŠ¤íŠ¸_ì „ì²´ë³‘í•©ë°ì´í„°_20251008.csv\"\n",
    "result_dir = \"/Users/yeong-gwang/Documents/ë°°ì›€ ì˜¤ì „ 1.38.42/ì™¸ë¶€/ê³µëª¨ì „/ë¹…ì½˜í…ŒìŠ¤íŠ¸/Project/work/ver3_/1012/result/3_ê°€ì„¤1ë¶„ì„\"\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"ì „ì²´ ë°ì´í„° í˜•íƒœ: {df.shape}\")\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¡œë“œ\n",
    "cluster_result = pd.read_csv(f\"{result_dir}/í´ëŸ¬ìŠ¤í„°ë§_ê²°ê³¼_ì™„ì „íŒ.csv\")\n",
    "print(f\"í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í˜•íƒœ: {cluster_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[íƒ€ê¹ƒ ë³€ìˆ˜ ë¶„í¬]\n",
      "y_close_3m\n",
      "0    88946\n",
      "1      457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "íì—… ë¹„ìœ¨: 0.51%\n"
     ]
    }
   ],
   "source": [
    "# íƒ€ê¹ƒ ë³€ìˆ˜ ìƒì„±: y_close_3m\n",
    "# ìƒíƒœê°€ 'D-3m'ì´ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "\n",
    "df_model = cluster_result.merge(df, on='ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', how='left')\n",
    "\n",
    "# íƒ€ê¹ƒ ë³€ìˆ˜ (D-3më§Œ 1, ë‚˜ë¨¸ì§€ 0)\n",
    "df_model['y_close_3m'] = (df_model['ìƒíƒœ'] == 'D-3m').astype(int)\n",
    "\n",
    "print(\"\\n[íƒ€ê¹ƒ ë³€ìˆ˜ ë¶„í¬]\")\n",
    "print(df_model['y_close_3m'].value_counts())\n",
    "print(f\"\\níì—… ë¹„ìœ¨: {df_model['y_close_3m'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í”¼ì²˜ ì„ íƒ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„ íƒëœ í”¼ì²˜ ê°œìˆ˜]: 168\n",
      "\n",
      "[ìƒìœ„ 10ê°œ í”¼ì²˜]:\n",
      "1. CPI_í’ˆëª©_ì›”ì„¸\n",
      "2. ë™ì¼ ì—…ì¢… ë§¤ì¶œê±´ìˆ˜ ë¹„ìœ¨\n",
      "3. CPI_ëª©ì _ìŒì‹ë°ìˆ™ë°•_ìˆ™ë°•ì„œë¹„ìŠ¤\n",
      "4. CPI_ëª©ì _ê¸°íƒ€ìƒí’ˆë°ì„œë¹„ìŠ¤_ë¯¸ìš©ìš©í’ˆë°ë¯¸ìš©ì„œë¹„ìŠ¤\n",
      "5. CPI_í’ˆëª©ìƒì„¸_ì„œë¹„ìŠ¤_ê³µê³µì„œë¹„ìŠ¤\n",
      "6. CPI_í’ˆëª©_êµ­ì‚°ì‡ ê³ ê¸°\n",
      "7. CPI_í’ˆëª©_ì¹˜ê³¼ì§„ë£Œë¹„\n",
      "8. ì‹ë£Œí’ˆ_ì§€ì¶œ_ì´ê¸ˆì•¡\n",
      "9. CPI_í’ˆëª©_íœ˜ë°œìœ \n",
      "10. ìƒí™œë¬¼ê°€ì§€ìˆ˜\n"
     ]
    }
   ],
   "source": [
    "# ì œì™¸í•  ì»¬ëŸ¼ (ì‹ë³„ì, íƒ€ê¹ƒ, ë‚ ì§œ ë“±)\n",
    "exclude_cols = {\n",
    "    'ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ê¸°ì¤€ë…„ì›”', 'ê¸°ì¤€ì—°ì›”', 'ê¸°ì¤€ë¶„ê¸°', 'ê°œì„¤ì¼', 'íì—…ì¼',\n",
    "    'ìƒíƒœ', 'y_close_3m', 'cluster',\n",
    "    'ì¢Œí‘œì •ë³´(X)', 'ì¢Œí‘œì •ë³´(Y)', 'ìƒê¶Œ_ì½”ë“œ', 'ìƒê¶Œ_ì½”ë“œ_ëª…'\n",
    "}\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ì„ íƒ\n",
    "all_cols = set(df_model.columns)\n",
    "feature_cols = list(all_cols - exclude_cols)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• í”¼ì²˜ë§Œ ì„ íƒ\n",
    "numeric_features = []\n",
    "for col in feature_cols:\n",
    "    if col in df_model.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_model[col]):\n",
    "            numeric_features.append(col)\n",
    "\n",
    "print(f\"\\n[ì„ íƒëœ í”¼ì²˜ ê°œìˆ˜]: {len(numeric_features)}\")\n",
    "print(f\"\\n[ìƒìœ„ 10ê°œ í”¼ì²˜]:\")\n",
    "for i, col in enumerate(numeric_features[:10], 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìµœì¢… ë°ì´í„° í˜•íƒœ: X=(89403, 168), y=(89403,)\n",
      "ê²°ì¸¡ì¹˜ ê°œìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X = df_model[numeric_features].copy()\n",
    "y = df_model['y_close_3m'].copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì¹˜\n",
    "for col in X.columns:\n",
    "    if X[col].isna().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "for col in X.columns:\n",
    "    if X[col].isna().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"\\nìµœì¢… ë°ì´í„° í˜•íƒœ: X={X.shape}, y={y.shape}\")\n",
    "print(f\"ê²°ì¸¡ì¹˜ ê°œìˆ˜: {X.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: (71522, 168), íì—…ë¥ =0.51%\n",
      "Test set: (17881, 168), íì—…ë¥ =0.51%\n"
     ]
    }
   ],
   "source": [
    "# 80:20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, íì—…ë¥ ={y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test set: {X_test.shape}, íì—…ë¥ ={y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ êµ¬ì¶• (reference.ipynb ë°©ë²•ë¡ )\n",
    "\n",
    "### 3ê°€ì§€ ëª¨ë¸:\n",
    "1. **LogisticRegression**: ë² ì´ìŠ¤ë¼ì¸\n",
    "2. **HistGradientBoostingClassifier**: ê¶Œì¥ ëª¨ë¸\n",
    "3. **RandomForestClassifier**: ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨ (0:1) = 194.4:1\n",
      "ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë° ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨ (0:1) = {pos_weight:.1f}:1\")\n",
    "\n",
    "# ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ìŠ¤ì¼€ì¼ë§)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ìˆ˜ë™ ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜\n",
    "def manual_oversample(X, y, random_state=42):\n",
    "    \"\"\"ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì™€ ê°™ì€ ìˆ˜ë¡œ ì˜¤ë²„ìƒ˜í”Œë§\"\"\"\n",
    "    # í´ë˜ìŠ¤ë³„ë¡œ ë¶„ë¦¬\n",
    "    X_maj = X[y == 0]\n",
    "    X_min = X[y == 1]\n",
    "    y_maj = y[y == 0]\n",
    "    y_min = y[y == 1]\n",
    "    \n",
    "    # ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜¤ë²„ìƒ˜í”Œë§\n",
    "    X_min_upsampled = resample(X_min, \n",
    "                                replace=True,\n",
    "                                n_samples=len(X_maj),\n",
    "                                random_state=random_state)\n",
    "    y_min_upsampled = np.ones(len(X_maj), dtype=int)\n",
    "    \n",
    "    # í•©ì¹˜ê¸°\n",
    "    X_resampled = pd.concat([X_maj, pd.DataFrame(X_min_upsampled, columns=X_min.columns)])\n",
    "    y_resampled = np.concatenate([y_maj, y_min_upsampled])\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "print(\"ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë° ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ëª¨ë¸ ì •ì˜ ì™„ë£Œ]\n",
      "- logit\n",
      "- hgb\n",
      "- rf_bal\n"
     ]
    }
   ],
   "source": [
    "# 1) Logistic Regression (ë² ì´ìŠ¤ë¼ì¸)\n",
    "logit = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) HistGradientBoosting (ê¶Œì¥ ëª¨ë¸)\n",
    "hgb = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=31,\n",
    "        min_samples_leaf=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3) RandomForest + ìˆ˜ë™ ì˜¤ë²„ìƒ˜í”Œë§\n",
    "# ì˜¤ë²„ìƒ˜í”Œë§ì€ í•™ìŠµ ì‹œ ì§ì ‘ ì ìš©\n",
    "rf_clf = Pipeline(steps=[\n",
    "    ('pre', preproc),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'logit': logit,\n",
    "    'hgb': hgb,\n",
    "    'rf_bal': rf_clf  # ì˜¤ë²„ìƒ˜í”Œë§ì€ í•™ìŠµ ì‹œ ì ìš©\n",
    "}\n",
    "\n",
    "print(\"\\n[ëª¨ë¸ ì •ì˜ ì™„ë£Œ]\")\n",
    "for name in models:\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[logit] í•™ìŠµ ì‹œì‘...\n",
      "============================================================\n",
      "\n",
      "[logit] ROC-AUC=1.000  PR-AUC=1.000  F1@0.5=1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000     17790\n",
      "           1      1.000     1.000     1.000        91\n",
      "\n",
      "    accuracy                          1.000     17881\n",
      "   macro avg      1.000     1.000     1.000     17881\n",
      "weighted avg      1.000     1.000     1.000     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[hgb] í•™ìŠµ ì‹œì‘...\n",
      "============================================================\n",
      "\n",
      "[hgb] ROC-AUC=1.000  PR-AUC=1.000  F1@0.5=1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000     17790\n",
      "           1      1.000     1.000     1.000        91\n",
      "\n",
      "    accuracy                          1.000     17881\n",
      "   macro avg      1.000     1.000     1.000     17881\n",
      "weighted avg      1.000     1.000     1.000     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[rf_bal] í•™ìŠµ ì‹œì‘...\n",
      "============================================================\n",
      "  ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© ì¤‘...\n",
      "  ì˜¤ë²„ìƒ˜í”Œë§ í›„: (142312, 168), íì—…ë¥ =50.00%\n",
      "\n",
      "[rf_bal] ROC-AUC=1.000  PR-AUC=0.993  F1@0.5=0.829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.998     0.999     17790\n",
      "           1      0.714     0.989     0.829        91\n",
      "\n",
      "    accuracy                          0.998     17881\n",
      "   macro avg      0.857     0.993     0.914     17881\n",
      "weighted avg      0.998     0.998     0.998     17881\n",
      "\n",
      "\n",
      "============================================================\n",
      "[ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[{name}] í•™ìŠµ ì‹œì‘...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # rf_balì˜ ê²½ìš° ì˜¤ë²„ìƒ˜í”Œë§ ì ìš©\n",
    "    if name == 'rf_bal':\n",
    "        print(\"  ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© ì¤‘...\")\n",
    "        X_train_balanced, y_train_balanced = manual_oversample(X_train, y_train, random_state=42)\n",
    "        print(f\"  ì˜¤ë²„ìƒ˜í”Œë§ í›„: {X_train_balanced.shape}, íì—…ë¥ ={y_train_balanced.mean()*100:.2f}%\")\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    if hasattr(model[-1], 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'ROC-AUC': roc,\n",
    "        'PR-AUC': pr,\n",
    "        'F1@0.5': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[{name}] ROC-AUC={roc:.3f}  PR-AUC={pr:.3f}  F1@0.5={f1:.3f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ]\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\n",
      "============================================================\n",
      "        ROC-AUC  PR-AUC  F1@0.5\n",
      "logit       1.0   1.000   1.000\n",
      "hgb         1.0   1.000   1.000\n",
      "rf_bal      1.0   0.993   0.829\n",
      "\n",
      "ğŸ† Best Model (ROC-AUC ê¸°ì¤€): logit (ROC-AUC=1.000)\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ DataFrame ìƒì„±\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[ìµœì¢… ì„±ëŠ¥ ë¹„êµ]\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Best model ì„ íƒ\n",
    "best_name = results_df.index[0]\n",
    "best_score = results_df.loc[best_name, 'ROC-AUC']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model (ROC-AUC ê¸°ì¤€): {best_name} (ROC-AUC={best_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: /Users/yeong-gwang/Documents/ë°°ì›€ ì˜¤ì „ 1.38.42/ì™¸ë¶€/ê³µëª¨ì „/ë¹…ì½˜í…ŒìŠ¤íŠ¸/Project/work/ver3_/1012/result/3_ê°€ì„¤1ë¶„ì„/11_ëª¨ë¸ì„±ëŠ¥_ë¹„êµê²°ê³¼.csv\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "results_df.to_csv(f\"{result_dir}/11_ëª¨ë¸ì„±ëŠ¥_ë¹„êµê²°ê³¼.csv\", encoding='utf-8-sig')\n",
    "print(f\"\\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_dir}/11_ëª¨ë¸ì„±ëŠ¥_ë¹„êµê²°ê³¼.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í•´ì„\n",
    "\n",
    "**ì‹¤ì œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ**:\n",
    "- 3ê°€ì§€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì§ì ‘ ë¹„êµ\n",
    "- ROC-AUC, PR-AUC, F1 Scoreë¡œ í‰ê°€\n",
    "- Best Modelì„ ì„ ì •í•˜ì—¬ ë³´ê³ ì„œì— ë°˜ì˜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
