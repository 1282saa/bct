{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b181e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "가설 1 완전판 클러스터링 분석 (현서님 방식)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "주요 구현 사항:\n",
    "1. 5단계 상태 라벨링 (정상영업, D-12m, D-9m, D-6m, D-3m)\n",
    "2. 구간형 변수 자동 인코딩\n",
    "3. 결측 50% 기준 변수 선택\n",
    "4. 최근월 스냅샷 클러스터링\n",
    "5. 임박비중 계산 (위험도 평가)\n",
    "6. LISA 공간분석 (High-High 핫스팟)\n",
    "7. 클러스터별 위험도 종합 평가\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"가설 1 완전판 클러스터링 분석 (현서님 방식)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528f7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "1. 데이터 로드 및 날짜 처리\n",
      "================================================================================\n",
      "데이터 형태: (86263, 192)\n",
      "기준년월 범위: 2023-01-01 00:00:00 ~ 2024-12-01 00:00:00\n",
      "폐업 가맹점: 2,334개\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. 데이터 로드 및 날짜 처리\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. 데이터 로드 및 날짜 처리\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_path = \"/Users/yeong-gwang/Documents/배움 오전 1.38.42/외부/공모전/빅콘테스트/Project/work/ver3_/1009/빅콘테스트_전체병합데이터_20251008.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 날짜 변환\n",
    "df['기준년월_dt'] = pd.to_datetime(df['기준년월'].astype(str), format='%Y%m', errors='coerce')\n",
    "\n",
    "# 폐업일 → Period M (현서님 방식)\n",
    "def _to_periodM_from_any(s):\n",
    "    s = s.astype(str).str.replace(r'\\.0$', '', regex=True).str.strip()\n",
    "    dt = pd.to_datetime(s, errors='coerce')\n",
    "    return dt.dt.to_period('M')\n",
    "\n",
    "df['_관측월'] = df['기준년월_dt'].dt.to_period('M')\n",
    "df['_폐업월'] = _to_periodM_from_any(df['폐업일'])\n",
    "\n",
    "# 개월차 계산 (양수 = 폐업 전, 음수 = 폐업 후)\n",
    "y1, m1 = df['_폐업월'].dt.year, df['_폐업월'].dt.month\n",
    "y0, m0 = df['_관측월'].dt.year, df['_관측월'].dt.month\n",
    "df['_months_to_close'] = (y1 - y0) * 12 + (m1 - m0)\n",
    "\n",
    "print(f\"데이터 형태: {df.shape}\")\n",
    "print(f\"기준년월 범위: {df['기준년월_dt'].min()} ~ {df['기준년월_dt'].max()}\")\n",
    "print(f\"폐업 가맹점: {df['_폐업월'].notna().sum():,}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3380a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "2. 5단계 상태 라벨링 (정상, D-12/9/6/3)\n",
      "================================================================================\n",
      "\n",
      "정상영업: 4,043개\n",
      "D-12m: 105개\n",
      "D-9m: 113개\n",
      "D-6m: 32개\n",
      "D-3m: 32개\n",
      "\n",
      "통합 데이터: 4,325개\n",
      "\n",
      "[상태 분포]:\n",
      "상태\n",
      "D-12m     105\n",
      "D-3m       32\n",
      "D-6m       32\n",
      "D-9m      113\n",
      "정상영업     4043\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. 5단계 상태 라벨링 \n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. 5단계 상태 라벨링 (정상, D-12/9/6/3)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 정상영업: 한번도 폐업 기록 없는 가맹점의 최신 데이터\n",
    "closed_any = df.groupby('가맹점구분번호')['_폐업월'].transform(lambda s: s.notna().any())\n",
    "normal_latest = (df[~closed_any]\n",
    "                 .sort_values(['가맹점구분번호', '기준년월_dt'])\n",
    "                 .groupby('가맹점구분번호', as_index=False)\n",
    "                 .tail(1)\n",
    "                 .assign(상태='정상영업'))\n",
    "\n",
    "print(f\"\\n정상영업: {len(normal_latest):,}개\")\n",
    "\n",
    "# 폐업 D-k: 각 가맹점에서 정확히 D-k 개월 전 스냅샷 1건\n",
    "def _pick_preclose(k):\n",
    "    sub = df[df['_months_to_close'].eq(k)].copy()\n",
    "    if sub.empty:\n",
    "        return sub.assign(상태=f'D-{k}m')\n",
    "    sub = (sub.sort_values(['가맹점구분번호', '기준년월_dt'])\n",
    "              .groupby('가맹점구분번호', as_index=False)\n",
    "              .tail(1))\n",
    "    sub['상태'] = f'D-{k}m'\n",
    "    return sub\n",
    "\n",
    "# 임박 시점 추출\n",
    "d12 = _pick_preclose(12)\n",
    "d9 = _pick_preclose(9)\n",
    "d6 = _pick_preclose(6)\n",
    "d3 = _pick_preclose(3)\n",
    "\n",
    "print(f\"D-12m: {len(d12):,}개\")\n",
    "print(f\"D-9m: {len(d9):,}개\")\n",
    "print(f\"D-6m: {len(d6):,}개\")\n",
    "print(f\"D-3m: {len(d3):,}개\")\n",
    "\n",
    "# 통합\n",
    "ana = pd.concat([normal_latest, d12, d9, d6, d3], ignore_index=True)\n",
    "\n",
    "# 상태 순서 정의\n",
    "STATUS_ORDER = [\"정상영업\", \"D-12m\", \"D-9m\", \"D-6m\", \"D-3m\"]\n",
    "STATUS_RANK = {s: i for i, s in enumerate(STATUS_ORDER)}\n",
    "ana['_상태_ord'] = ana['상태'].map(STATUS_RANK)\n",
    "\n",
    "print(f\"\\n통합 데이터: {len(ana):,}개\")\n",
    "print(\"\\n[상태 분포]:\")\n",
    "print(ana['상태'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e0a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "3. 구간형 변수 자동 인코딩\n",
      "================================================================================\n",
      "\n",
      "후보 변수 수: 177개\n",
      "✓ 수치형 변환 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. 구간형 변수 자동 인코딩\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. 구간형 변수 자동 인코딩\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def encode_bucket_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"구간형 변수를 숫자로 변환 (정규식 추출 → 실패시 빈도순)\"\"\"\n",
    "    ser = s.astype(str)\n",
    "    head_num = ser.str.extract(r'^(\\d+)', expand=False)\n",
    "    out = pd.to_numeric(head_num, errors='coerce')\n",
    "\n",
    "    if out.notna().any() and out.isna().mean() < 0.5:\n",
    "        return out\n",
    "\n",
    "    # 실패 시 빈도순\n",
    "    ser = s.fillna('N/A').astype(str)\n",
    "    order = ser.value_counts().index.tolist()\n",
    "    mapping = {v: i+1 for i, v in enumerate(order)}\n",
    "    return ser.map(mapping).astype(float)\n",
    "\n",
    "def to_numeric_smart(df_in: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    \"\"\"모든 컬럼을 숫자형으로 변환\"\"\"\n",
    "    df2 = df_in.copy()\n",
    "    for c in cols:\n",
    "        if c.endswith('구간'):\n",
    "            df2[c] = encode_bucket_series(df2[c])\n",
    "        else:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors='coerce')\n",
    "        # 센티널 제거\n",
    "        df2.loc[df2[c] < -1e8, c] = np.nan\n",
    "    return df2\n",
    "\n",
    "# 분석 후보 변수\n",
    "exclude_cols = {\n",
    "    '가맹점구분번호', '기준년월', '기준연월', '기준분기', '개설일', '폐업일',\n",
    "    '상권_코드', '상권_코드_명', '구분지역', '지역명',\n",
    "    '업종', '상태', '_상태_ord', '기준년월_dt',\n",
    "    '_폐업월', '_관측월', '_months_to_close'\n",
    "}\n",
    "\n",
    "cand_cols = [c for c in ana.columns if c not in exclude_cols]\n",
    "print(f\"\\n후보 변수 수: {len(cand_cols)}개\")\n",
    "\n",
    "# 수치형 변환\n",
    "ana_num = to_numeric_smart(ana, cand_cols)\n",
    "\n",
    "# 기본 컬럼 복원\n",
    "for col in ['가맹점구분번호', '상태', '_상태_ord', '기준년월_dt']:\n",
    "    if col in ana.columns:\n",
    "        ana_num[col] = ana[col]\n",
    "\n",
    "print(\"✓ 수치형 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980c98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4. 변수 선택 (결측 50% 기준)\n",
      "================================================================================\n",
      "\n",
      "선택된 변수 수: 175개\n",
      "좌표 데이터 존재: True\n",
      "\n",
      "변수 유형:\n",
      "  - 구간형: 6개\n",
      "  - 수치형: 169개\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. 변수 선택 (결측 50% 기준)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. 변수 선택 (결측 50% 기준)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 좌표 컬럼 확인\n",
    "XCOL, YCOL = '좌표정보(X)', '좌표정보(Y)'\n",
    "has_coords = (XCOL in ana_num.columns) and (YCOL in ana_num.columns)\n",
    "\n",
    "# 결측 50% 이하인 수치형 변수\n",
    "feat_cols = [c for c in cand_cols\n",
    "             if pd.api.types.is_numeric_dtype(ana_num[c])\n",
    "             and ana_num[c].notna().mean() > 0.5]\n",
    "\n",
    "print(f\"\\n선택된 변수 수: {len(feat_cols)}개\")\n",
    "print(f\"좌표 데이터 존재: {has_coords}\")\n",
    "\n",
    "# 구간형/수치형 분류\n",
    "bucket_cols = [c for c in feat_cols if c.endswith('구간')]\n",
    "numeric_cols = [c for c in feat_cols if not c.endswith('구간')]\n",
    "\n",
    "print(f\"\\n변수 유형:\")\n",
    "print(f\"  - 구간형: {len(bucket_cols)}개\")\n",
    "print(f\"  - 수치형: {len(numeric_cols)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e3a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "5. 클러스터링 데이터 준비\n",
      "================================================================================\n",
      "\n",
      "결측치 처리 중...\n",
      "\n",
      "변수 행렬 형태: (4325, 175)\n",
      "✓ 스케일링 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. 클러스터링 데이터 준비\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. 클러스터링 데이터 준비\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 클러스터링용 데이터\n",
    "cluster_df = ana_num[['가맹점구분번호', '상태', '_상태_ord'] + feat_cols].copy()\n",
    "\n",
    "# 좌표 추가 (LISA용)\n",
    "if has_coords:\n",
    "    cluster_df[XCOL] = ana_num[XCOL]\n",
    "    cluster_df[YCOL] = ana_num[YCOL]\n",
    "\n",
    "# 결측치 처리 (중앙값)\n",
    "print(\"\\n결측치 처리 중...\")\n",
    "for c in feat_cols:\n",
    "    if cluster_df[c].isna().any():\n",
    "        median_val = cluster_df[c].median(skipna=True)\n",
    "        cluster_df[c] = cluster_df[c].fillna(median_val)\n",
    "\n",
    "# 변수 행렬\n",
    "X = cluster_df[feat_cols].values\n",
    "print(f\"\\n변수 행렬 형태: {X.shape}\")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"✓ 스케일링 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43b1250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "6. K-means 클러스터링 (n_init=30)\n",
      "================================================================================\n",
      "\n",
      "k=3~7 평가 중...\n",
      "  k=3: Silhouette=0.5956, DB=1.1781\n",
      "  k=4: Silhouette=0.3169, DB=1.2489\n",
      "  k=5: Silhouette=0.2193, DB=1.4818\n",
      "  k=6: Silhouette=0.1614, DB=1.5612\n",
      "  k=7: Silhouette=0.1673, DB=1.4742\n",
      "\n",
      "최적 k: 3 (Silhouette=0.5956)\n",
      "✓ 클러스터 할당 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 6. K-means 클러스터링\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. K-means 클러스터링 (n_init=30)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# k 선택\n",
    "k_range = range(3, 8)\n",
    "evaluation_results = []\n",
    "\n",
    "print(\"\\nk=3~7 평가 중...\")\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=30, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    db_score = davies_bouldin_score(X_scaled, labels)\n",
    "    inertia = kmeans.inertia_\n",
    "\n",
    "    evaluation_results.append({\n",
    "        'k': k,\n",
    "        'silhouette': silhouette,\n",
    "        'davies_bouldin': db_score,\n",
    "        'inertia': inertia\n",
    "    })\n",
    "\n",
    "    print(f\"  k={k}: Silhouette={silhouette:.4f}, DB={db_score:.4f}\")\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "best_k = eval_df.loc[eval_df['silhouette'].idxmax(), 'k']\n",
    "best_silhouette = eval_df.loc[eval_df['silhouette'].idxmax(), 'silhouette']\n",
    "\n",
    "print(f\"\\n최적 k: {best_k} (Silhouette={best_silhouette:.4f})\")\n",
    "\n",
    "# 최종 클러스터링\n",
    "kmeans_final = KMeans(n_clusters=best_k, n_init=30, random_state=42)\n",
    "cluster_df['cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"✓ 클러스터 할당 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8822ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "7. 임박비중 계산 (위험도 평가)\n",
      "================================================================================\n",
      "\n",
      "클러스터별 임박비중:\n",
      "         가맹점수    정상  D12  D9  D6  D3      임박비중    위험도\n",
      "cluster                                              \n",
      "0         198     0   94  67  20  17  1.000000  🔴 고위험\n",
      "2          46     0   11  12  10  13  1.000000  🔴 고위험\n",
      "1        4081  4043    0  34   2   2  0.009311   ✅ 정상\n",
      "\n",
      "고위험 클러스터: [0, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 7. 임박비중 계산 \n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. 임박비중 계산 (위험도 평가)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 클러스터별 상태 분포\n",
    "cluster_risk = cluster_df.groupby('cluster').agg(\n",
    "    가맹점수=('가맹점구분번호', 'count'),\n",
    "    정상=('상태', lambda s: (s == '정상영업').sum()),\n",
    "    D12=('상태', lambda s: (s == 'D-12m').sum()),\n",
    "    D9=('상태', lambda s: (s == 'D-9m').sum()),\n",
    "    D6=('상태', lambda s: (s == 'D-6m').sum()),\n",
    "    D3=('상태', lambda s: (s == 'D-3m').sum())\n",
    ")\n",
    "\n",
    "# 비율 계산\n",
    "cluster_risk['정상_비율'] = cluster_risk['정상'] / cluster_risk['가맹점수']\n",
    "cluster_risk['D12_비율'] = cluster_risk['D12'] / cluster_risk['가맹점수']\n",
    "cluster_risk['D9_비율'] = cluster_risk['D9'] / cluster_risk['가맹점수']\n",
    "cluster_risk['D6_비율'] = cluster_risk['D6'] / cluster_risk['가맹점수']\n",
    "cluster_risk['D3_비율'] = cluster_risk['D3'] / cluster_risk['가맹점수']\n",
    "\n",
    "# 임박비중 (D-12/9/6/3 합계)\n",
    "cluster_risk['임박비중'] = (\n",
    "    cluster_risk['D12_비율'] +\n",
    "    cluster_risk['D9_비율'] +\n",
    "    cluster_risk['D6_비율'] +\n",
    "    cluster_risk['D3_비율']\n",
    ")\n",
    "\n",
    "# 위험도 등급 부여\n",
    "cluster_risk['위험도'] = cluster_risk['임박비중'].apply(\n",
    "    lambda x: '🔴 고위험' if x > 0.05 else ('🟡 중위험' if x > 0.02 else '✅ 정상')\n",
    ")\n",
    "\n",
    "cluster_risk = cluster_risk.sort_values('임박비중', ascending=False)\n",
    "\n",
    "print(\"\\n클러스터별 임박비중:\")\n",
    "print(cluster_risk[['가맹점수', '정상', 'D12', 'D9', 'D6', 'D3', '임박비중', '위험도']])\n",
    "\n",
    "# 고위험 클러스터 식별\n",
    "high_risk_clusters = cluster_risk[cluster_risk['임박비중'] > 0.05].index.tolist()\n",
    "print(f\"\\n고위험 클러스터: {high_risk_clusters if high_risk_clusters else '없음'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee49253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "8. LISA 공간분석 (핫스팟 식별)\n",
      "================================================================================\n",
      "\n",
      "좌표 데이터: 4,325개\n",
      "✓ LISA 분석 완료\n",
      "\n",
      "클러스터별 High-High 비율:\n",
      "            HH_비율  HH_유의\n",
      "cluster                 \n",
      "2        0.929078    131\n",
      "0        0.804734    246\n",
      "1        0.003152    540\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 8. LISA 공간분석 (High-High 핫스팟)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. LISA 공간분석 (핫스팟 식별)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "lisa_result = None\n",
    "\n",
    "if has_coords:\n",
    "    try:\n",
    "        from libpysal.weights import KNN\n",
    "        from esda.moran import Moran_Local\n",
    "        from shapely.geometry import Point\n",
    "        import geopandas as gpd\n",
    "\n",
    "        # 좌표 유효한 데이터만\n",
    "        df_spatial = cluster_df[\n",
    "            cluster_df[XCOL].notna() &\n",
    "            cluster_df[YCOL].notna()\n",
    "        ].copy()\n",
    "\n",
    "        print(f\"\\n좌표 데이터: {len(df_spatial):,}개\")\n",
    "\n",
    "        if len(df_spatial) >= 30:  # 최소 표본 수\n",
    "            # GeoDataFrame 생성\n",
    "            df_spatial['geometry'] = df_spatial.apply(\n",
    "                lambda row: Point(row[XCOL], row[YCOL]), axis=1\n",
    "            )\n",
    "            gdf = gpd.GeoDataFrame(df_spatial, geometry='geometry')\n",
    "\n",
    "            # 위험 점수 계산 (임박비중 기반)\n",
    "            risk_scores = cluster_df.groupby('cluster')['_상태_ord'].mean()\n",
    "            df_spatial['risk_score'] = df_spatial['cluster'].map(risk_scores)\n",
    "\n",
    "            # k-NN 가중치 (k=8)\n",
    "            w = KNN.from_dataframe(gdf, k=min(8, len(gdf)-1))\n",
    "\n",
    "            # Local Moran's I\n",
    "            lisa = Moran_Local(df_spatial['risk_score'].values, w)\n",
    "\n",
    "            # 사분면 분류\n",
    "            y_z = (df_spatial['risk_score'] - df_spatial['risk_score'].mean()) / df_spatial['risk_score'].std()\n",
    "            lz = lisa.Is - lisa.Is.mean()\n",
    "\n",
    "            quad = np.where((y_z > 0) & (lz > 0), 'High-High',\n",
    "                    np.where((y_z < 0) & (lz < 0), 'Low-Low',\n",
    "                    np.where((y_z > 0) & (lz < 0), 'High-Low',\n",
    "                    np.where((y_z < 0) & (lz > 0), 'Low-High', 'Undefined'))))\n",
    "\n",
    "            df_spatial['LISA_quad'] = quad\n",
    "            df_spatial['LISA_sig'] = lisa.p_sim < 0.05\n",
    "\n",
    "            # 결과 병합\n",
    "            cluster_df = cluster_df.merge(\n",
    "                df_spatial[['가맹점구분번호', 'LISA_quad', 'LISA_sig']],\n",
    "                on='가맹점구분번호',\n",
    "                how='left'\n",
    "            )\n",
    "\n",
    "            # High-High 비율\n",
    "            lisa_summary = cluster_df.groupby('cluster').agg(\n",
    "                HH_비율=('LISA_quad', lambda s: (s == 'High-High').mean()),\n",
    "                HH_유의=('LISA_sig', lambda s: s.sum())\n",
    "            )\n",
    "\n",
    "            cluster_risk = cluster_risk.merge(lisa_summary, left_index=True, right_index=True)\n",
    "\n",
    "            print(\"✓ LISA 분석 완료\")\n",
    "            print(\"\\n클러스터별 High-High 비율:\")\n",
    "            print(lisa_summary.sort_values('HH_비율', ascending=False))\n",
    "\n",
    "            lisa_result = {\n",
    "                'total_points': len(df_spatial),\n",
    "                'high_high_count': (df_spatial['LISA_quad'] == 'High-High').sum(),\n",
    "                'high_high_sig': ((df_spatial['LISA_quad'] == 'High-High') & df_spatial['LISA_sig']).sum()\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ 좌표 데이터 부족 (최소 30개 필요, 현재 {len(df_spatial)}개)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ LISA 분석 실패: {e}\")\n",
    "        print(\"   (libpysal, esda 패키지 설치 필요: pip install libpysal esda)\")\n",
    "else:\n",
    "    print(\"⚠️ 좌표 데이터 없음 (LISA 분석 건너뜀)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ae7c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "9. 클러스터 프로파일링\n",
      "================================================================================\n",
      "\n",
      "분산 기준 상위 10개 변수:\n",
      "  1. 당월_매출_금액\n",
      "  2. 주중_매출_금액\n",
      "  3. 지출_총금액\n",
      "  4. 시간대_17~21_매출_금액\n",
      "  5. 시간대_11~14_매출_금액\n",
      "  6. 주말_매출_금액\n",
      "  7. 시간대_21~24_매출_금액\n",
      "  8. 금요일_매출_금액\n",
      "  9. 식료품_지출_총금액\n",
      "  10. 목요일_매출_금액\n",
      "\n",
      "클러스터별 평균:\n",
      "             당월_매출_금액      주중_매출_금액        지출_총금액  시간대_17~21_매출_금액  \\\n",
      "cluster                                                              \n",
      "0        5.421365e+08  3.977223e+08  9.507291e+08     2.250469e+08   \n",
      "1        8.096208e+08  6.059382e+08  9.613653e+08     3.190997e+08   \n",
      "2        1.471308e+09  1.085152e+09  9.067863e+08     5.808036e+08   \n",
      "\n",
      "         시간대_11~14_매출_금액      주말_매출_금액  시간대_21~24_매출_금액     금요일_매출_금액  \\\n",
      "cluster                                                                 \n",
      "0           1.233092e+08  1.444142e+08     9.087301e+07  9.376870e+07   \n",
      "1           2.111237e+08  2.036832e+08     1.284699e+08  1.374322e+08   \n",
      "2           3.891280e+08  3.861569e+08     2.360576e+08  2.494707e+08   \n",
      "\n",
      "           식료품_지출_총금액     목요일_매출_금액  \n",
      "cluster                              \n",
      "0        2.590808e+08  8.399966e+07  \n",
      "1        2.634176e+08  1.256317e+08  \n",
      "2        2.480732e+08  2.321746e+08  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 9. 클러스터 프로파일링\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. 클러스터 프로파일링\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 상위 10개 중요 변수\n",
    "feature_variance = cluster_df[feat_cols].var().sort_values(ascending=False)\n",
    "top_features = feature_variance.head(10).index.tolist()\n",
    "\n",
    "print(f\"\\n분산 기준 상위 10개 변수:\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# 클러스터별 평균 (원값)\n",
    "cluster_profile = cluster_df.groupby('cluster')[top_features].mean().round(2)\n",
    "\n",
    "print(\"\\n클러스터별 평균:\")\n",
    "print(cluster_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3797495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "10. 결과 저장\n",
      "================================================================================\n",
      "✓ 클러스터 할당 결과 저장\n",
      "✓ 임박비중 통계 저장\n",
      "✓ k 평가 결과 저장\n",
      "✓ 클러스터 프로파일 저장\n",
      "✓ 종합 요약 JSON 저장\n",
      "✓ 상세 보고서 저장\n",
      "\n",
      "================================================================================\n",
      "가설 1 완전판 클러스터링 분석 완료!\n",
      "================================================================================\n",
      "✅ 5단계 상태 라벨링 완료\n",
      "✅ 최적 k: 3\n",
      "✅ Silhouette Score: 0.5956\n",
      "✅ 고위험 클러스터: 2개\n",
      "✅ LISA High-High 핫스팟: 199개\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 10. 결과 저장\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. 결과 저장\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_dir = \"/Users/yeong-gwang/Documents/배움 오전 1.38.42/외부/공모전/빅콘테스트/Project/work/ver3_/1012/result/3_가설1분석\"\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1) 클러스터 할당 결과\n",
    "result_df = cluster_df[['가맹점구분번호', 'cluster', '상태', '_상태_ord']].copy()\n",
    "if 'LISA_quad' in cluster_df.columns:\n",
    "    result_df['LISA_quad'] = cluster_df['LISA_quad']\n",
    "    result_df['LISA_sig'] = cluster_df['LISA_sig']\n",
    "\n",
    "result_df.to_csv(f\"{output_dir}/클러스터링_결과_완전판.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"✓ 클러스터 할당 결과 저장\")\n",
    "\n",
    "# 2) 임박비중 통계\n",
    "cluster_risk.to_csv(f\"{output_dir}/클러스터_임박비중_완전판.csv\", encoding='utf-8-sig')\n",
    "print(\"✓ 임박비중 통계 저장\")\n",
    "\n",
    "# 3) k 평가 결과\n",
    "eval_df.to_csv(f\"{output_dir}/클러스터_개수_평가_완전판.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"✓ k 평가 결과 저장\")\n",
    "\n",
    "# 4) 클러스터 프로파일\n",
    "cluster_profile.to_csv(f\"{output_dir}/클러스터_프로파일_완전판.csv\", encoding='utf-8-sig')\n",
    "print(\"✓ 클러스터 프로파일 저장\")\n",
    "\n",
    "# 5) 종합 요약 JSON\n",
    "summary = {\n",
    "    \"분석일\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"분석방법\": \"현서님 방식 완전판\",\n",
    "    \"상태라벨\": STATUS_ORDER,\n",
    "    \"상태분포\": {\n",
    "        \"정상영업\": int((cluster_df['상태'] == '정상영업').sum()),\n",
    "        \"D-12m\": int((cluster_df['상태'] == 'D-12m').sum()),\n",
    "        \"D-9m\": int((cluster_df['상태'] == 'D-9m').sum()),\n",
    "        \"D-6m\": int((cluster_df['상태'] == 'D-6m').sum()),\n",
    "        \"D-3m\": int((cluster_df['상태'] == 'D-3m').sum())\n",
    "    },\n",
    "    \"변수수\": len(feat_cols),\n",
    "    \"최적k\": int(best_k),\n",
    "    \"Silhouette_Score\": float(best_silhouette),\n",
    "    \"고위험_클러스터\": [int(c) for c in high_risk_clusters],\n",
    "    \"클러스터별_임박비중\": {\n",
    "        str(int(k)): float(v)\n",
    "        for k, v in cluster_risk['임박비중'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "if lisa_result:\n",
    "    summary['LISA분석'] = {\n",
    "        'total_points': int(lisa_result['total_points']),\n",
    "        'high_high_count': int(lisa_result['high_high_count']),\n",
    "        'high_high_sig': int(lisa_result['high_high_sig'])\n",
    "    }\n",
    "\n",
    "with open(f\"{output_dir}/클러스터링_요약_완전판.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "print(\"✓ 종합 요약 JSON 저장\")\n",
    "\n",
    "# 6) 상세 보고서\n",
    "report = f\"\"\"# 가설 1 클러스터링 분석 완전판 (현서님 방식)\n",
    "\n",
    "**분석일**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "**분석 대상**: 가맹점 {len(cluster_df):,}개\n",
    "---\n",
    "\n",
    "## 📊 1. 분석 개요\n",
    "\n",
    "### 1.1 5단계 상태 라벨링\n",
    "\n",
    "| 상태 | 가맹점 수 | 비율 | 설명 |\n",
    "|------|-----------|------|------|\n",
    "| 정상영업 | {(cluster_df['상태']=='정상영업').sum():,}개 | {(cluster_df['상태']=='정상영업').sum()/len(cluster_df)*100:.1f}% | 최근월 정상 가맹점 |\n",
    "| D-12m | {(cluster_df['상태']=='D-12m').sum():,}개 | {(cluster_df['상태']=='D-12m').sum()/len(cluster_df)*100:.1f}% | 폐업 12개월 전 |\n",
    "| D-9m | {(cluster_df['상태']=='D-9m').sum():,}개 | {(cluster_df['상태']=='D-9m').sum()/len(cluster_df)*100:.1f}% | 폐업 9개월 전 |\n",
    "| D-6m | {(cluster_df['상태']=='D-6m').sum():,}개 | {(cluster_df['상태']=='D-6m').sum()/len(cluster_df)*100:.1f}% | 폐업 6개월 전 |\n",
    "| D-3m | {(cluster_df['상태']=='D-3m').sum():,}개 | {(cluster_df['상태']=='D-3m').sum()/len(cluster_df)*100:.1f}% | 폐업 3개월 전 |\n",
    "\n",
    "### 1.2 클러스터링 설정\n",
    "\n",
    "- **알고리즘**: K-means\n",
    "- **변수 수**: {len(feat_cols)}개 (결측 50% 기준)\n",
    "- **스케일링**: StandardScaler\n",
    "- **n_init**: 30 (초기값 의존성 감소)\n",
    "- **최적 k**: {best_k}\n",
    "- **Silhouette Score**: {best_silhouette:.4f}\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 2. 클러스터별 임박비중 (위험도)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for cluster_id in cluster_risk.index:\n",
    "    row = cluster_risk.loc[cluster_id]\n",
    "    report += f\"\"\"\n",
    "### 클러스터 {cluster_id} {row['위험도']}\n",
    "\n",
    "- **가맹점 수**: {int(row['가맹점수']):,}개 ({row['가맹점수']/len(cluster_df)*100:.1f}%)\n",
    "- **정상**: {int(row['정상'])}개 ({row['정상_비율']*100:.1f}%)\n",
    "- **D-12m**: {int(row['D12'])}개 ({row['D12_비율']*100:.1f}%)\n",
    "- **D-9m**: {int(row['D9'])}개 ({row['D9_비율']*100:.1f}%)\n",
    "- **D-6m**: {int(row['D6'])}개 ({row['D6_비율']*100:.1f}%)\n",
    "- **D-3m**: {int(row['D3'])}개 ({row['D3_비율']*100:.1f}%)\n",
    "- **임박비중**: {row['임박비중']*100:.2f}%\n",
    "\"\"\"\n",
    "\n",
    "    if 'HH_비율' in row.index:\n",
    "        report += f\"- **High-High 비율**: {row['HH_비율']*100:.2f}%\\n\"\n",
    "\n",
    "report += \"\"\"\n",
    "---\n",
    "\n",
    "## 📈 3. 가설 검증 결과\n",
    "\n",
    "### ✅ 가설 1: 채택\n",
    "\n",
    "**가설**: 5개 지표군에 따른 상권 세분화가 가능하다\n",
    "\n",
    "**근거**:\n",
    "\"\"\"\n",
    "\n",
    "report += f\"\"\"\n",
    "1. ✅ {best_k}개 클러스터로 세분화 성공\n",
    "2. ✅ 클러스터별 임박비중 차이 확인\n",
    "3. ✅ 고위험 클러스터 식별: {len(high_risk_clusters)}개\n",
    "4. ✅ Silhouette Score: {best_silhouette:.4f}\n",
    "\"\"\"\n",
    "\n",
    "if lisa_result:\n",
    "    report += f\"\"\"\n",
    "5. ✅ LISA 공간분석 완료\n",
    "   - High-High 핫스팟: {lisa_result['high_high_count']}개\n",
    "   - 유의한 핫스팟: {lisa_result['high_high_sig']}개\n",
    "\"\"\"\n",
    "\n",
    "report += \"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 4. 정책적 시사점\n",
    "\n",
    "### 4.1 고위험 클러스터 집중 지원\n",
    "\"\"\"\n",
    "\n",
    "if high_risk_clusters:\n",
    "    for cluster_id in high_risk_clusters:\n",
    "        row = cluster_risk.loc[cluster_id]\n",
    "        report += f\"\\n**클러스터 {cluster_id}**:\\n\"\n",
    "        report += f\"- 가맹점 수: {int(row['가맹점수']):,}개\\n\"\n",
    "        report += f\"- 임박비중: {row['임박비중']*100:.2f}%\\n\"\n",
    "        report += f\"- 즉각적인 경영 컨설팅 및 재정 지원 필요\\n\"\n",
    "else:\n",
    "    report += \"\\n- 현재 고위험 클러스터 없음 (양호)\\n\"\n",
    "\n",
    "report += \"\"\"\n",
    "\n",
    "### 4.2 조기 경보 시스템\n",
    "- 클러스터별 임박비중 모니터링\n",
    "- 임박비중 5% 이상 → 경고 발령\n",
    "\n",
    "### 4.3 지역 기반 정책 (LISA 활용)\n",
    "\"\"\"\n",
    "\n",
    "if lisa_result:\n",
    "    report += \"\"\"\n",
    "- High-High 핫스팟 지역 우선 지원\n",
    "- 공간적 파급효과 차단\n",
    "\"\"\"\n",
    "else:\n",
    "    report += \"- LISA 분석 미실시 (좌표 데이터 부족)\\n\"\n",
    "\n",
    "report += \"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 생성 파일\n",
    "\n",
    "1. **클러스터링_결과_완전판.csv**: 가맹점별 클러스터 + 상태 + LISA\n",
    "2. **클러스터_임박비중_완전판.csv**: 클러스터별 위험도 통계\n",
    "3. **클러스터_개수_평가_완전판.csv**: k=3~7 평가\n",
    "4. **클러스터_프로파일_완전판.csv**: 클러스터별 변수 평균\n",
    "5. **클러스터링_요약_완전판.json**: JSON 요약\n",
    "6. **이 파일**: 상세 보고서\n",
    "\n",
    "---\n",
    "\n",
    "**작성자**: Claude Code\n",
    "**분석 프레임워크**: Python 3.12, scikit-learn, K-means, LISA\n",
    "**참고**: 현서님 레퍼런스 방식 완전 재현\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{output_dir}/가설1_클러스터링_완전판_보고서.md\", 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "print(\"✓ 상세 보고서 저장\")\n",
    "\n",
    "# ============================================================================\n",
    "# 완료\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"가설 1 완전판 클러스터링 분석 완료!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✅ 5단계 상태 라벨링 완료\")\n",
    "print(f\"✅ 최적 k: {best_k}\")\n",
    "print(f\"✅ Silhouette Score: {best_silhouette:.4f}\")\n",
    "print(f\"✅ 고위험 클러스터: {len(high_risk_clusters)}개\")\n",
    "if lisa_result:\n",
    "    print(f\"✅ LISA High-High 핫스팟: {lisa_result['high_high_count']}개\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23920d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
